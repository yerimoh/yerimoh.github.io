---
title: "Deep learning: BERT êµ¬í˜„, ì½”ë“œ ì„¤ëª…"
date:   2020-01-17
excerpt: ""
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# ëª©ì°¨



----
---

ğŸ‘€, ğŸ¤·â€â™€ï¸ , ğŸ“œ    
ì´ ì•„ì´ì½˜ë“¤ì„ ëˆ„ë¥´ì‹œë©´ ì½”ë“œ, ê°œë… ë¶€ê°€ ì„¤ëª…ì„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:)

---
----


# INRTO


**[ëª©í‘œ]**              
ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëŒ€ê·œëª¨ ê³ ì„±ëŠ¥ Transformer ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸í˜ ì‚¬ìš©í•˜ì—¬ NLP ì‘ì—…,   
* **0) ë°ì´í„° ì‚´í´ë³´ê¸°**: NCBI ì§ˆë³‘ ì–¸ì–´ ìë£Œì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ì„¸íŠ¸ë¥¼ ì‚¬ìš©     
* **1) pretraining:** í…ìŠ¤íŠ¸ ë¶„ë¥˜        
* **2) fine tuning:** NER(ëª…ëª…ëœ ì—”í„°í‹° ì¸ì‹)êµ¬ì¶•   





**[ì½ê¸° ìœ„í•´ í•„ìš”í•œ ì§€ì‹]**    
* [attention](https://yerimoh.github.io/DL19/)             
* [transformer](https://yerimoh.github.io/Lan/): ì •ë§ ë¬´ì¡°ê±´ë¬´ì¡°ê±´ ì •ë…í•˜ì ì´ê±° ì½ê³ ì˜¤ë©´ ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” ê»Œì´ë‹¤.            
* [bert](https://yerimoh.github.io/Lan2/)    

**[ì› ë…¼ë¬¸]**          
[Attention is All You Need](https://arxiv.org/abs/1706.03762)              
[bert](https://arxiv.org/pdf/1810.04805.pdf)              
  
      



---
---

# **0) ë°ì´í„° ì‚´í´ë³´ê¸°**
**[Corpus Annotated Data]**     
  

<details>
<summary>ğŸ“œ </summary>
<div markdown="1">

 
  
</div>
</details> 




















