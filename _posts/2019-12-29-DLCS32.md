---
title: "[32] CS2241N: Lecture 2 Word Vectors 2 and Word Window Classification ì •ë¦¬"
date:   2019-12-29
excerpt: "Lecture 2 | Word Vectors 2 and Word Window Classification ìš”ì•½"  
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# ëª©ì°¨
- [**INTRO**](#--intro--)
- [**Word2vec2**](#--word2vec2--)
  * [negative sampling](#negative-sampling)
  * [aside](#aside)
  * [co-occurrence matrix](#co-occurrence-matrix)
- [**GLOVE**](#--glove--)
  * [evaluate word vectors](#evaluate-word-vectors)
    + [Intrinsic](#intrinsic)
    + [Extrinsic](#extrinsic)
- [**Word senses and word sense ambiguity**](#--word-senses-and-word-sense-ambiguity--)





-----

# **INTRO**

**[Review: Main idea of word2vec]**   
* [word2vec ê°•ì˜ ì •ë¦¬ ë³´ëŸ¬ê°€ê¸°](https://yerimoh.github.io/DLCS31/)       
* random word vectorsë¡œ ì‹œì‘í•œë‹¤.     
* ë‹¨ì–´ì— ëŒ€í•œ ë‹¨ì–´ ë²¡í„°ì™€ ë¬¸ë§¥ë²¡í„° ì‚¬ì´ì˜ ë‚´ì ì˜ ê´€ì ì—ì„œ ì•„ë˜ í™•ë¥ ë¶„í¬ ì‹ìœ¼ë¡œ ì´ë¥¼ ìˆ˜í–‰        
![image](https://user-images.githubusercontent.com/76824611/179308881-20a77774-79f5-44ce-9eac-4e172297e873.png)
![image](https://user-images.githubusercontent.com/76824611/179224320-f4af78e2-281e-4ef9-92be-a9e25e80aaa9.png)
* **í•™ìŠµ**      
   * ë²¡í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ ì£¼ë³€ ë‹¨ì–´ ì˜ˆì¸¡ì„ ë” ì˜í•˜ê²Œ í•œë‹¤.        
   * ì´ëŸ¬í•œ í•™ìŠµì„ í†µí•´ ë²¡í„°ëŠ” ê³ ì°¨ì›ì—ì„œ ìœ ì‚¬ì„±ì´ ë†’ì€ ë‹¨ì–´ë“¤ê³¼ ê°€ê¹Œì´ ìˆê³  ì˜ë¯¸ìˆëŠ” ë°©í–¥ì„ ê°–ê²Œëœë‹¤.       


<details>
<summary>ğŸ‘€ ê°•ì˜ ìŠ¬ë¼ì´ë“œ ë³´ê¸°</summary>
<div markdown="1">
  
![image](https://user-images.githubusercontent.com/76824611/178133425-7ff3b02a-118f-451a-8636-cded1f948e5c.png)

  
</div>
</details>

------

# **Word2vec2**    
Word2vec2ëŠ” Word2vecì˜ ë‹¨ì ì„ ë³´ì™„í•œ ê²ƒìœ¼ë¡œ í¬ê²Œ 2ê°€ì§€ ë³´ì™„ì ì„ ê°–ê³  ë‚˜ì˜¨ ê²ƒì´ë‹¤.    
* negative sampling    
* [embedding](https://yerimoh.github.io/DL15/#1%EF%B8%8F%E2%83%A3-embedding-%EA%B3%84%EC%B8%B5-%EB%8F%84%EC%9E%85)     

ê·¸ëŸ°ë° ê°•ì˜ì—ëŠ” ì´ ë‘ê°€ì§€ ë³´ì™„ì  ì¤‘ negative samplingë§Œ ì„¤ëª…í•œë‹¤ê³  ë˜ì–´ìˆì–´ ë‚´ê°€ ë”°ë¡œ ì •ë¦¬í•´ë‘” embedding í¬ìŠ¤íŒ… ë§í¬ë¥¼ ì¶”ê±°í•´ë’€ë‹¤.     
ê¶ê¸ˆí•˜ë©´ ì½ì–´ë³´ë©´ ëœë‹¤.     


**[Word2vec parametersì˜ íŠ¹ì§•]**     
* Word2vecì˜ ìœ ì¼í•œ ë§¤ê°œë³€ìˆ˜(parameters)ëŠ” ë‹¨ì–´ë²¡í„°ì´ë‹¤.          
* Word2vecëŠ” â€œBag of wordsâ€ model ì´ë‹¤.      
    * Bag of words: ë‹¨ì–´ì˜ ìˆœì„œì™€ ìœ„ì¹˜ë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤.      
    * ì¦‰, ë¬¸ë§¥ì•ˆì— ìˆëŠ” ë‹¨ì–´ë“¤ì€ ëª¨ë‘ ê°™ì€ ì·¨ê¸‰ì„ ë°›ëŠ”ë‹¤ëŠ” ê²ƒì´ë‹¤.            
* ê° ë‹¨ì–´ì— ëŒ€í•´ ì™¸ë¶€ë‹¨ì–´ ë²¡í„°(outside), ì¤‘ì•™ë‹¨ì–´ ë²¡í„°ê°€ ìˆë‹¤.     
![image](https://user-images.githubusercontent.com/76824611/179228387-1b9f4383-004e-4a42-95a0-448ecff23ace.png)



**[Word2vec parametersì˜ ê³„ì‚°ê³¼ì •]**        
* **1)** íŠ¹ì • ì™¸ë¶€ ë‹¨ì–´ê°€ ì¤‘ì‹¬ ë‹¨ì–´ì™€ í•¨ê»˜ ë°œìƒí•  ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ì–»ê¸° ìœ„í•´ target ë²¡í„°ì™€ context ë²¡í„°ë¥¼ ë‚´ì ì„ ì·¨í•œë‹¤.   
* **2)** ì´ ì •ìˆ˜ë¥¼ í™•ë¥ ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ì„œ softmaxë¥¼ ì‚¬ìš©í•œë‹¤.     
![image](https://user-images.githubusercontent.com/76824611/179228402-5b4df729-d505-4d4d-a28f-d519af32a110.png)





**[Word2vec in space]**     
* í•™ìŠµ ê²°ê³¼ ë¹„ìŠ·í•œ ë‹¨ì–´ë¼ë¦¬ ê³ ì°¨ì› ê³µê°„ì— ê°€ê¹ê²Œ ë°°ì¹˜ë˜ì–´ìˆë‹¤.     
* ì´ ê³ ì°¨ì› ê³µê°„ì€ ìš°ë¦¬ê°€ ì•„ëŠ” 2ì°¨ì›ê³¼ ë‹¤ë¥´ê²Œ ìƒê²¼ë‹¤.       
![image](https://user-images.githubusercontent.com/76824611/179245067-928be223-a29b-45b4-81e1-11d09e5588e7.png)



**[Optimization: (Stochastic) Gradient Descent]**     
* **Gradient Descent**: ëª¨ë“  ë²¡í„°ë¥¼ í•œêº¼ë²ˆì— ì—…ë°ì´íŠ¸   
  * ëŠë¦¼       
  * ìš°ë¦¬ê°€ ì•ì—ì„œ ë°°ì› ë˜ $$J(Î¸)$$ê°€ GDì„               
* **Stochastic Gradient Descent**: ë§ë­‰ì¹˜ë¥¼ ë°°ì¹˜ë‹¨ìœ„ë¡œ ìª¼ê°œ ë°°ì¹˜ë‹¨ìœ„ë¡œ ì—…ë°ì´íŠ¸    
  * ë¹ ë¦„      
  * ì´ê±¸ ëŒ€ë¶€ë¶„ ë§ì´ ì”€      
* **Optimization ê³¼ì •**       
  * 1) ë¬´ì‘ìœ„(0ì— ê°€ê¹Œìš´ ìˆ«ìë“¤)ë¡œ ë‹¨ì–´ë²¡í„°ì˜ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”(randon initial value)        
  * 2) ì§€ë‚œì‹œê°„ì— ì •ì˜í•œ ì†ì‹¤í•¨ìˆ˜ $$J(Î¸)$$ë¡œ ì†ì‹¤ì„ ê³„ì‚°í•œ ë‹¤ìŒ ì†ì‹¤ê°’ì´ ë‚®ì€ ê³³ìœ¼ë¡œ ê¸°ìš¸ê¸° í•˜ê°•        
* ì´ ìµœì í™”ì˜ ì•„ì´ë””ì–´ëŠ” í˜„ì¬ ìœ„ì¹˜ì—ì„œ í˜„ê°œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•œ ë‹¤ìŒ ìŒì˜ ê¸°ìš¸ê¸° ë°©í–¥ìœ¼ë¡œ **ì‘ì€ ê±¸ìŒ**ì„ ë‚´ë”›ìŒ      
* **step size(learning step)**: ì‘ì€ ê±¸ìŒì˜ ë³´í­        
  * ì´ ì‚¬ì´ì¦ˆê°€ ë„ˆë¬´ í¬ë©´ ì™”ë‹¤ê°”ë‹¤í•¨     
  * ì´ ì‚¬ì´ì¦ˆê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ í•™ìŠµì´ ì˜¤ë˜ê±¸ë¦¼      
  * ê·¸ëŸ¬ë¯€ë¡œ ì ì ˆí•¨ ì‚¬ì´ì¦ˆë¡œ ì¡°ì •í•˜ëŠ”ê²ƒì´ ì¤‘ìš”í•¨      
* ìœ„ì™€ ê°™ì´ ìµœì í™”í•˜ì—¬ ì†ì‹¤ê°’ì´ ë‚®ì€(minimum) ì¢‹ì€ ë‹¨ì–´ ë²¡í„°ë¥¼ ë§Œë“œëŠ”ê²ƒì´ ëª©í‘œ     
![image](https://user-images.githubusercontent.com/76824611/179247632-1e48b880-f72e-4ff7-b15a-34a5c1f5914e.png)




**[Word2vec algorithm family: More details]**     
* ì™œ **2ê°œ**ì˜ ë²¡í„°ì¸ê°€?(ì™œ ë” ë§ì€ ë²¡í„°ë¥¼ ë³´ì§€ ì•Šê³  2ê°œì˜ ë²¡í„°ë§Œ ë³´ê³  ê³„ì‚°ì— í¬í•¨ì‹œí‚¤ëŠ”ê°€?)     
   * ìš°ë¦¬ê°€ ë³´ê¸°ë¡œí•œ ë²¡í„°ë“¤ì€ ë²¡í„°ë¼ë¦¬ ë‚´ì ì„ ìˆ˜í–‰í•´ì•¼í•˜ëŠ”ë° 2ê°œë¥¼ ë„˜ì–´ê°€ë©´ **ê³„ì‚°**ì´ ë„ˆë¬´ **ë³µì¡**í•´ì ¸ì„œ ì˜¤íˆë ¤ ë” ë¹„íš¨ìœ¨ì ì´ë‹¤.     
   * íŠ¹íˆ ë¶„ëª¨ë¥¼ ê³„ì‚°í•˜ëŠ”ê²Œ ë„ˆë¬´ costê°€ ë†’ë‹¤.     
* **Word2vecì˜ ëª¨ë¸**     
   * Word2vecëŠ” 2ê°œì˜ ëª¨ë¸ì„ ì•„ìš°ë¥´ëŠ” í‘œí˜„ì´ë‹¤.      
   * **1) [Skip-grams (SG)](https://yerimoh.github.io/DL14/#skip-gram-%EB%AA%A8%EB%8D%B8)**: targetë‹¨ì–´ë¡œ contextë‹¨ì–´ ì˜ˆì¸¡(ì„±ëŠ¥ì´ ì¢‹ì•„ì„œ ë” ë§ì´ ì”€)(ì´ ê°•ì˜ì—ì„œ ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ê²ƒ)     
   * **2) [Continuous Bag of Words (CBOW)](https://yerimoh.github.io/DL14/#cbow-%EB%AA%A8%EB%8D%B8)**: contextë‹¨ì–´ë¡œ targetë‹¨ì–´ ì˜ˆì¸¡            
    



<details>
<summary>ğŸ‘€ ê°•ì˜ ìŠ¬ë¼ì´ë“œ ë³´ê¸°</summary>
<div markdown="1">
  
![image](https://user-images.githubusercontent.com/76824611/179227583-15fc6e6a-2fda-467d-b469-28e3cc130a75.png)
![image](https://user-images.githubusercontent.com/76824611/179245132-c72cabbc-eed4-4349-8554-46841879b7e2.png)
![image](https://user-images.githubusercontent.com/76824611/179249318-5861b727-f8b9-470e-8a5b-d6afed0ed40f.png)
![image](https://user-images.githubusercontent.com/76824611/179249359-6af99138-237d-49e7-8ec2-f7e1b80894d7.png)

  
</div>
</details>


-----


## negative sampling
Word2vecë¥¼ ë” ìµœì í™”í•˜ê¸° ìœ„í•œ ë°©ë²• ì¤‘ í•˜ë‚˜ì´ë‹¤.      
ì´ ê°•ì˜ì—ì„  skip-gramì˜ negative sampling (SGNS)ìœ„ì£¼ë¡œ ì„¤ëª…í•˜ê² ë‹¤.        


**[ê¸°ì¡´ skip-gramì˜ ë¬¸ì œ]**       
* ì•„ë˜ skip-gramì˜ ì‹ì„ ë³´ë©´ ë¶„ëª¨ê°€ ëª¨ë“  ë‹¨ì–´ì˜ ë‚´ì ì„ ìˆ˜í–‰í•´ì•¼í•˜ê¸° ë•Œë¬¸ì— ê³„ì‚°ì´ ë„ˆë¬´ ë¹„ì‹¸ë‹¤.      
* ê·¸ëŸ¬ë¯€ë¡œ ëª¨ë“  ë‚´ì ì˜ í‰ê· ì„ ë‚´ëŠ” ```softmax```ëŒ€ì‹  ```negative sampling```ì„ ìˆ˜í–‰í•´ì•¼í•œë‹¤.    
![image](https://user-images.githubusercontent.com/76824611/179309792-e3710d21-b389-45fc-a410-6bf714975d8a.png)

<details>
<summary>ğŸ“œ more about Softmax classifier ë³´ê¸°</summary>
<div markdown="1">
  
![image](https://user-images.githubusercontent.com/76824611/179307890-24828139-7cc1-4293-8f02-89618def92a5.png)
  
</div>
</details>  



**[negative sampling: $$maximize$$]**     
* ì—¬ëŸ¬ "noise" ìŒ(random ë‹¨ì–´ì™€ ì§ì„ ì´ë£¨ëŠ” center ë‹¨ì–´) ëŒ€ë¹„ true ìŒ(center ë‹¨ì–´ì™€ contextì°½ì˜ ë‹¨ì–´)ì— ëŒ€í•œ ì´í•­ ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ì„ í›ˆë ¨
* Overall objective function($$maximize$$)         
   * $$logğœ(u_{o}^{T} v_{c})$$: ì •ë‹µ ìŒì˜ ë‚´ì ì„ í†µí•´ ë‘ ë‹¨ì–´ê°€ ë™ì‹œì— ë°œìƒí•  í™•ë¥ ì„ ìµœëŒ€í™”      
   * $$ \sum_{i=1}^{k} E_{j~P(w)}[logğœ(-u_{j}^{T} v_{c}] $$: ì •ë‹µì´ ì•„ë‹Œ ì˜¤ë‹µê°’ ì¤‘ì—ì„œ ëœë¤ìœ¼ë¡œ ì„ íƒí•˜ì—¬ ì˜¤ë‹µê°’ì„ í•™ìŠµì‹œì¼œ ë‹¨ì–´ì˜ í™•ë¥ ì„ ìµœì†Œí™”, ì¦‰ ì†Œìˆ˜ì˜ ë¬´ì‘ìœ„ì˜ ë‹¨ì–´ì— ëŒ€í•´ ê³„ì‚°í•œë‹¤.(ë¬´ì‘ìœ„ ë‹¨ì–´ë¥¼ ìƒ˜í”Œë§í•˜ëŠ” ë¹„ìœ¨ì€ í™•ë¥ ì— ë”°ë¼ ë‹¤ë¥´ë‹¤)         
![image](https://user-images.githubusercontent.com/76824611/179262441-47905dd3-b358-4471-bf6d-cbe0c635a155.png)
* ì—¬ê¸°ì„œ softmax ëŒ€ì‹  **sigmoid(ğœ)** ë¥¼ ì‚¬ìš©í•œë‹¤      
   * sigmoid = logisitc í•¨ìˆ˜ ì´ë‹¤.        
   * ì´ê±¸ í†µí•´ì„œ ì¤‘ì‹¬ë‹¨ì–´ì™€ ë¬´ì‘ìœ„ë¡œ ê³ ë¥¸ ë‹¨ì–´ ì‚¬ì´ì˜ ë‚´ì ì„ êµ¬í•œë‹¤.    
   * ì´ sigmoidë¥¼ í†µí•˜ë©´ ì´ ë‚´ì ê°’ì´ í¬ë©´ ì‚¬ì‹¤ìƒ 1, ì•„ë‹ˆë©´ 0ì´ ëœë‹¤.    
   * ì´í•´ê°€ ì•ˆê°„ë‹¤ë©´? [ë” ì•Œì•„ë³´ê¸°](https://yerimoh.github.io/DL15/#%EB%84%A4%EA%B1%B0%ED%8B%B0%EB%B8%8C-%EC%83%98%ED%94%8C%EB%A7%81)  
![image](https://user-images.githubusercontent.com/76824611/179262929-1a22dcce-5b2a-446d-8b20-07a75ace8a51.png)

<details>
<summary>ğŸ“œ more about binary logistic regression ë³´ê¸°</summary>
<div markdown="1">
  
 
![image](https://user-images.githubusercontent.com/76824611/179308149-8752a9c2-382d-4955-81f4-0a2bae73e569.png)
  ![image](https://user-images.githubusercontent.com/76824611/179308178-04ffbf75-6710-4f42-a4d1-b13472b21588.png)
![image](https://user-images.githubusercontent.com/76824611/179308196-d712f638-28c5-4cc5-89ae-c52fdbcdcbc8.png)
![image](https://user-images.githubusercontent.com/76824611/179308214-c9d6a242-b586-4fc3-8091-c03849be5819.png)

  
</div>
</details>  


**[negative sampling: $$minimize$$]**     
* ì´ ê°•ì˜ì—ì„œ ë‚´ì£¼ëŠ” ê³¼ì œë¥¼ ìœ„í•´ ìœ„ì˜ ì‹ì„ ì¡°ê¸ˆ ë” ë¶„ì„í•´ë´¤ë‹¤.       
   * ì´ ì‹ì€ ìŒì˜ ë¡œê·¸ ê°€ëŠ¥ì„±ì„ ìµœì†Œí™” í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.    
   * ì¦‰ ìœ„ì˜ ì‹ì—ë‹¤ -ë¥¼ ë¶™ì´ê³  ì´ë¥¼ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ë‹¤.       
   * ê° ì‹ì— ëŒ€í•œ ì„¤ëª…ì€ ìœ„ì™€ ê°™ë‹¤.(ëŒ€ì‹  ê±°ê¸°ì— ìŒì„ ì·¨í•œë‹¤ëŠ” ê²ƒë§Œ ë‹¤ë¥´ë‹¤)        
   * $$k$$:negative samples (using word probabilities)      
![image](https://user-images.githubusercontent.com/76824611/179264744-a8a232f6-d5d4-4b2d-8324-c2521c14fc40.png)
* ì‹¤ì œ **ì™¸ë¶€ ë‹¨ì–´**ê°€ ë‚˜íƒ€ë‚  **í™•ë¥ ** **ìµœëŒ€í™”**, ì¤‘ì‹¬ ë‹¨ì–´ ì£¼ë³€ì— ì„ì˜ ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚  í™•ë¥  ìµœì†Œí™”     
â¡ ì´ë¥¼ í†µí•´ ì£¼ë³€ ë‹¨ì–´ì—ë§Œ êµ­í•œëœ í•™ìŠµì´ ì•„ë‹Œ ì¢€ ë” ì „ì²´ë¥¼ ê³ ë ¤í•œ í•™ìŠµì´ ëœë‹¤.     
* $$P(w)= U(w)^{3/4}/Z$$ì˜ í™•ë¥ ë¡œ ë¶€ì •ì ì¸ ì˜ˆë¥¼ ìƒ˜í”Œë§í•œë‹¤.     
    * ì •ë‹µì´ ì•„ë‹Œ ìƒ˜í”Œ(negative sample)ì„ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§ í•  ë•Œ ë‹¨ì–´ë“¤ì˜ ì¶œë³€ ë¹ˆë„ë¡œ ìƒ˜í”Œë§í•  ë‹¨ì–´ë¥¼ ë½‘ëŠ” ê²ƒì´ ì›ì¹™ì´ë‹¤.    
ê·¸ëŸ°ë° ë§ë­‰ì¹˜ ì¶œí˜„ ë¹ˆë„ê°€ ë‚®ì€ ì •ë‹µì´ ì•„ë‹Œ ìƒ˜í”Œì€ ì„ íƒë  í™•ë¥ ì´ ë‚®ë‹¤.      
ê·¸ëŸ¬ë¯€ë¡œ ê¸°ë³¸ í™•ë¥ ($$U(w)$$)ì— $$3/4$$ì„ ì œê³±í•˜ì—¬ **ë‚®ì€ ë¹ˆë„ì˜ ë‹¨ì–´ê°€ ì„ íƒë  í™•ë¥ ì„ ë†’ì´ëŠ” ê²ƒ**ì´ë‹¤.    
    * ì´í•´ê°€ ì•ˆê°„ë‹¤ë©´? [ë” ì•Œì•„ë³´ê¸°](https://yerimoh.github.io/DL15/#%EB%84%A4%EA%B1%B0%ED%8B%B0%EB%B8%8C-%EC%83%98%ED%94%8C%EB%A7%81%EC%9D%98-%EC%83%98%ED%94%8C%EB%A7%81-%EA%B8%B0%EB%B2%95)     





**[negative samplingì˜ ì¥ì ]**    
* softmaxë³´ë‹¤ íš¨ìœ¨ì    
  * softmaxëŠ” ë‚´ì ì´ ë§ì€ë° ëª¨ë“  ë‹¨ì–´ë¥¼ ëª¨ë‘ ë‚´ì í•˜ë ¤ë©´ ê³„ì‚°ë¹„ìš©, ì‹œê°„ì´ ìƒë‹¹í•˜ë‹¤.      
  * ë°˜ë©´, negative samplingì€ ëª¨ë“  ê²ƒì„ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ì •ë‹µê°’ê³¼ ì •ë‹µì´ ì•„ë‹Œ ê°’ì„ ê°ê° ì´ì§„(ì •ë‹µì´ë‹¤, ì •ë‹µì´ ì•„ë‹ˆë‹¤)ë¶„ë¥˜í•˜ì—¬ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— í™•ë¥ ì„ êµ¬í•˜ëŠ” softmaxë³´ë‹¤ íš¨ìœ¨ì ì´ë‹¤.         
  ![image](https://user-images.githubusercontent.com/76824611/179268880-eab2ddcc-19d2-4f7c-9718-ac25f0dc7a58.png)  
* context ë²”ìœ„ì— ì—†ëŠ” ë‹¨ì–´ë¥¼ negative samplingí•˜ì—¬ contextì—ë§Œ êµ­í•œëœ í•™ìŠµì—ì„œ ë²—ì–´ë‚  ìˆ˜ ìˆë‹¤.        



<details>
<summary>ğŸ‘€ ê°•ì˜ ìŠ¬ë¼ì´ë“œ ë³´ê¸°</summary>
<div markdown="1">
  
![image](https://user-images.githubusercontent.com/76824611/179269649-c93edcaf-ecf1-4346-87cc-b4fed3ca7e40.png)
![image](https://user-images.githubusercontent.com/76824611/179269686-024c9965-91d1-4893-9066-5033375ac064.png)
![image](https://user-images.githubusercontent.com/76824611/179269728-fe22b264-dc83-45d8-8dfb-9fabb62293d0.png)

  
</div>
</details>


------


## aside 
word2vecì—ì„œ ì¶”ê°€ ì§€ì‹(TMI)ì„ ìŒ“ì•„ë³´ì!


**[Stochastic gradients with negative sampling]**      
* ìš°ë¦¬ëŠ” SGDì— ëŒ€í•´ ê° ì°½ì—ì„œ ê·¸ë ˆì´ë””ì–¸íŠ¸ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì¸¡ì •í•œë‹¤.    
* ê·¸ëŸ°ë° ë§¤ stepë§ˆë‹¤ ì—…ë°ì´íŠ¸ ë˜ëŠ” ë²¡í„°ëŠ” ë§¤ìš°ë§¤ìš° í¬ì†Œí•˜ë‹¤.      
![image](https://user-images.githubusercontent.com/76824611/179284710-2b93fb2c-cff2-421f-a7a7-f311687629c5.png)


**[ë²¡í„°ì˜ í‘œí˜„]**      
* í˜„ì¬ëŠ” ê³„ì† ë‹¨ì–´ë¥¼ ì—´ë²¡í„°ë¡œ í‘œí˜„í–ˆì§€ë§Œ, ì‚¬ì‹¤ìƒ ì§ì ‘ ì»´í“¨í„°ë¡œ ê³„ì‚°í•œë•ŒëŠ” í–‰(row)ë²¡í„°ë¡œ í‘œí˜„ëœë‹¤.    
* í–‰ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ì—°ì†ìœ¼ë¡œ ê³„ì‚°ì´ ê°€ëŠ¥í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ê¸° ë–„ë¬¸ì´ë‹¤.         
![image](https://user-images.githubusercontent.com/76824611/179309741-dd60c069-e534-433b-b1fb-f1a17dd73108.png)


<details>
<summary>ğŸ“œ nore about neural word vectors ë³´ê¸°</summary>
<div markdown="1">
 
![image](https://user-images.githubusercontent.com/76824611/179308031-625cb572-7a0b-446c-a008-54431fa610d3.png)
  
  
</div>
</details>  


<details>
<summary>ğŸ‘€ ê°•ì˜ ìŠ¬ë¼ì´ë“œ ë³´ê¸°</summary>
<div markdown="1">
  
![image](https://user-images.githubusercontent.com/76824611/179290962-79e16661-7f54-4ef3-961a-afaf8b610152.png)
![image](https://user-images.githubusercontent.com/76824611/179290976-d2cbfcf0-71fa-454f-9f19-81938e6c79f1.png)
![image](https://user-images.githubusercontent.com/76824611/179291005-ca7138a6-8bd1-4ef8-9305-d382e4d42416.png)

  
</div>
</details>


-----

## co-occurrence matrix
ê·¸ë ‡ë‹¤ë©´ ì™œ ë‹¨ì–´ ë²¡í„°ë¥¼ í‘œí˜„í•  ë•Œ ë™ì‹œë°œìƒ í–‰ë ¬(co-occurrence matrix)ì„ **ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ê°€**?      

ë™ì‹œë°œìƒí–‰ë ¬(co-occurrence matrix)ì€ í†µê³„ê¸°ë°˜ ê¸°ë²•ì´ë‹¤.    

* **í†µê³„ê¸°ë°˜ ê¸°ë²•**      
   * í•œë‹¨ì–´ë¥¼ ë§ë­‰ì¹˜ ì „ì²´ë¥¼ ì´ìš©í•˜ì—¬ í‘œí˜„     
   * ë§ë­‰ì¹˜ê°€ ì¡°ê¸ˆ ìˆ˜ì •ë˜ë„ ëª¨ë“  ë‹¨ì–´ë¥¼ ì—…ë°ì´íŠ¸ í•´ì•¼í•¨    
   * ë¹„íš¨ìœ¨ì        
   * [PMI](https://yerimoh.github.io/DL13/#%EC%83%81%ED%98%B8%EC%A0%95%EB%B3%B4%EB%9F%89-pmi),**SVD**ë“±ì„ í†µí•´ì„œ ì°¨ì› ì¶•ì†Œë¥¼ í†µí•´ í•„ìš”ì—†ëŠ” ë‹¨ì–´ í‘œí˜„ ì •ë³´ë¥¼ ì—†ì• ë©´ì„œ ì„±ëŠ¥ ê°œì„     
* **ì¶”ë¡ ê¸°ë°˜ ê¸°ë²•**      
   * í•œ ë‹¨ì–´ë¥¼ í‘œí˜„í•  ë•Œ ë§ë­‰ì¹˜ ì „ì²´ê°€ ì•„ë‹Œ ëª‡ê°œì˜ ë‹¨ì–´ë¡œ ì¶”ë¡ í•˜ì—¬ ë‹¨ì–´ í‘œí˜„    
   * ë§ë­‰ì¹˜ê°€ ì¡°ê¸ˆ ìˆ˜ì •ë˜ì–´ë„ ì´ì— ì˜í–¥ì„ ë°›ëŠ” ëª‡ëª‡ ë‹¨ì–´ ë²¡í„°ë§Œ ìˆ˜ì •í•˜ë©´ ë¨     
   * ë¹„êµì  íš¨ìœ¨ì        



**[ë™ì‹œë°œìƒí–‰ë ¬(co-occurrence matrix) ì˜ˆì‹œ]**     
* ê° í‘œì˜ ì¹¸ì˜ ìˆ«ìì˜ ì˜ë¯¸ëŠ” ê·¸ ë‹¨ì–´ê°€ ë‚˜ì˜¤ëŠ” íšŸìˆ˜ì´ë‹¤.    
* Window length 1 (more common: 5â€“10)    
* Symmetric (irrelevant whether left or right context)     
* Example corpus:    
   * I like deep learning  
   * I like NLP   
   * I enjoy flying     

![image](https://user-images.githubusercontent.com/76824611/179309696-fa8b8643-8a0e-4a50-8488-7c50663ab07a.png)


**[ë™ì‹œë°œìƒí–‰ë ¬ì˜ ë¬¸ì œì ]**      
* **ë‹¨ìˆœíˆ ê°œìˆ˜ë¥¼ ì„¼ ë²¡í„°ì˜ ë¬¸ì œ**      
   * ë²¡í„°ê°€ ë§ë­‰ì¹˜ ì „ì²´ë¡œ í‘œí˜„ë˜ê¸° ë•Œë¬¸ì— ì–´íœ˜ì— ë”°ë¼ í¬ê¸°ê°€ ì»¤ì§„ë‹¤.       
   * ë§¤ìš° ë†’ì€ dimensional: ë§ì€ ì €ì¥ì†Œ í•„ìš”      
   * í›„ì† ë¶„ë¥˜ ëª¨ë¸ì€ í¬ì†Œì„± ë¬¸ì œê°€ ìˆë‹¤ â†’ ëª¨ë¸ì€ ëœ ê²¬ê³ í•˜ë‹¤.        
   * ì°¨ì›ì´ ë‚®ì•„ ëª¨ë¸ì´ ê²°ê³ í•˜ì§€ ëª»í•˜ë‹¤.           
* **í•´ê²°ì±…**       
   * ì¤‘ìš”í•œ ì •ë³´ì˜ "ëŒ€ë¶€ë¶„"ì„ ì†Œìˆ˜ì˜ ê³ ì •ëœ ì •ë³´ì— ì €ì¥ ì°¨ì›: **ë°€ì§‘ ë²¡í„°**    
   * ì´ë ‡ê²Œ ê¸°ì¡´ ë²¡í„°ë¥¼ ë°€ì§‘ ë²¡í„°ë¥¼ ë²¡í„°ë¥¼ í†µí•´ í‘œí˜„í•˜ë©´ word2vecì™€ ë¹„ìŠ·í•´ì§„ë‹¤.(Usually 25â€“1000 dimensions)      



**[í•´ê²°ì±…: SVD]**    
* ìœ„ ë¬¸ì œì˜ í•´ê²° ë°©ë²•ìœ¼ë¡œ ì°¨ì›ì´ ë‚®ì€ ë‹¨ìˆœ ë²¡í„°ë¥¼ ë°€ì§‘ ë²¡í„°ë¡œ ë§Œë“œëŠ” ê²ƒì´ë‹¤.      
* ì›ë˜ xë¥¼ ì•„ë˜ì™€ ê°™ì´ 3ê°œë¡œ ë‚˜ëˆ  í‘œí˜„í•œë‹¤.      
  * $$ğ›´$$ëŠ” ë†’ì€ ìˆ˜(ì¤‘ìš”í•œ ìˆ˜, ë¹ˆë„ê°€ ë†’ì€ ìˆ˜)ë¡œ ì •ë ¬ë˜ì–´ìˆì–´ ë” ë†’ì€ ë°€ì§‘ë„ì˜ ë²¡í„°ë¥¼ ì–»ê³ ì‹¶ìœ¼ë©´ ì´ í–‰ë ¬ì˜ ì•„ë˜(íŒŒë€ìƒ‰)ë¶€í„° ì§€ì›Œ ì¤‘ìš”í•œ ì •ë³´ë§Œ ë‚˜íƒ€ë‚´ê²Œí•˜ë©´ ëœë‹¤.     
  * ë…¸ë€ìƒ‰ ë¶€ë¶„ì´ ì—†ì–´ì§€ë©° ë¬´ì‹œëœë‹¤.       
* ì´í•´ê°€ ì•ˆëœë‹¤ë©´? [ë” ì•Œì•„ë³´ê¸°](https://yerimoh.github.io/DL13.3/) â¡ ê°™ì€ LSAì™€ ê°™ì€ ë§¥ë½ì´ë‹¤.        
![image](https://user-images.githubusercontent.com/76824611/179289682-6faa51bb-ded2-46a5-a769-018f025b3c67.png)


**[SVDì˜ ë¬¸ì œ í•´ê²°]**    
* **ë¬¸ì œì **    
  * ìœ„ì™€ ê°™ì€ SVDë¥¼ í†µí•´ ì¤‘ìš”í•œ ë‹¨ì–´(ë¹ˆë„ê°€ ë†’ì€ ë‹¨ì–´)ìœ„ì£¼ë¡œ í‘œí˜„í•˜ë©´  function words (the, he, has)ê°€ ë§ì´ ì¶”ì¶œëœë‹¤.    
  * ì´ëŠ” ì˜ë¯¸ì™€ ì—°ê´€ì´ ì—†ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ ì´ëŸ¬í•œ ë‹¨ì–´ë“¤ì´ ë¬¸ì œê°€ ëœë‹¤.       
* **í•´ê²°ì±…: Hacks to X**     
  * ìœ„ì™€ ê°™ì´ ë„ˆë¬´ ë¹ˆë„ê°€ ë†’ì€ ë‹¨ì–´ë“¤ì„ ì§€ì›Œì¤€ë‹¤.     
      * log the frequencies    
      * min(X, t), with t â‰ˆ 100   
      * Ignore the function words     
   * ì¹´ìš´íŠ¸ ëŒ€ì‹  Pearson ìƒê´€ ê´€ê³„ë¥¼ ì‚¬ìš©í•œ ë‹¤ìŒ ìŒìˆ˜ ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •í•œë‹¤.     
* **ë¬¸ì œ í•´ê²° ê²°ê³¼**    
   * ë‹¨ì–´ì˜ ìƒê´€ê´€ê³„ë¥¼ ë³´ë©´ ì˜ í•™ìŠµë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.    
   ![image](https://user-images.githubusercontent.com/76824611/179290742-62e87293-756c-4d19-84df-d7080f31e850.png)


<details>
<summary>ğŸ‘€ ê°•ì˜ ìŠ¬ë¼ì´ë“œ ë³´ê¸°</summary>
<div markdown="1">
  
![image](https://user-images.githubusercontent.com/76824611/179291123-29729b0e-8c3a-48eb-8857-24d3976baf2d.png)
![image](https://user-images.githubusercontent.com/76824611/179291140-4c412fae-9f0d-4aac-8a95-359236eded05.png)
![image](https://user-images.githubusercontent.com/76824611/179291150-d6ee7567-10ef-4579-a4a0-563d0e7cfdf3.png)
![image](https://user-images.githubusercontent.com/76824611/179291170-061688cf-87f4-4147-8bbd-1da057ed69b2.png)
![image](https://user-images.githubusercontent.com/76824611/179291187-3332e6d5-bce4-4407-98cf-b3a75a70618b.png)
![image](https://user-images.githubusercontent.com/76824611/179291220-3d63515b-b667-41b0-b6b0-60bc09e5e823.png)

  
</div>
</details>

-------
-----

# **GLOVE**     

**[Towards GloVe: Count based vs. direct prediction]**     
* **Count based**    
  * ë¹ ë¥¸ í•™ìŠµ  
  * í†µê³„ì˜ íš¨ìœ¨ì  ì‚¬ìš©       
  * ì£¼ë¡œ ë‹¨ì–´ ìœ ì‚¬ì„±ì„ í¬ì°©í•˜ëŠ” ë° ì‚¬ìš©ë¨     
  * ì£¼ì–´ì§„ ë§ë­‰ì¹˜ì— ëŒ€í•œ ë‹¨ì–´ ê°œìˆ˜ì˜ ë¶ˆê· í˜•      
  * ex) ```LSA```, ```HAL```, ```COALS```, ```Hellinger-PCA```      
* **direct prediction**     
  * ë§ë­‰ì¹˜ í¬ê¸°ë¥¼ Scales     
  * í†µê³„ì˜ ë¹„íš¨ìœ¨ì  ì‚¬ìš©     
  * ë‹¤ë¥¸ ì‘ì—…ì—ì„œ í–¥ìƒëœ ì„±ëŠ¥ ìƒì„±    
  * ë‹¨ì–´ì˜ ìœ ì‚¬ì„±ì„ ë„˜ì€ ë³µì¡í•œ íŒ¨í„´ í¬ì°©ê°€ëŠ¥     
  * ex) ```Skip-gram```/```CBOW```, ```NNLM```, ```HLBL```, ```RNN```     


**[Encoding meaning components in vector differences]**    
* ìœ ì¶”ë¬¸ì œ(meaning components)ë¥¼ í’€ê¸° ìœ„í•´ì„œëŠ” ë™ì‹œë°œìƒí™•ë¥ ì˜ ë¹„ìœ¨ë¡œ í‘œê¸°í•´ì•¼í•œë‹¤.    
  * 'ice'ì™€ ì—°ê´€ìˆëŠ” 'solid', 'water'ì˜ ë™ì‹œ ë°œìƒ ë¹„ìœ¨ì€ 'large'      
  * 'ice'ì™€ ì—°ê´€ì—†ëŠ” 'gas', ' random'ì˜ ë™ì‹œ ë°œìƒ ë¹„ìœ¨ì€ 'samll'    
  ![image](https://user-images.githubusercontent.com/76824611/179300317-0e7dab6f-90bc-44b3-874d-9ac0be2c5524.png)
* ì´ë¥¼ ìˆ˜ì¹˜í™”í•´ë³´ë©´,     
  * ë¹„ìŠ·í•œ ìˆ˜ì¹˜ë¼ë¦¬ëŠ” 1ì— ê°€ê¹Œìš´ ìˆ˜ê°€ ë‚˜ì˜¨ë‹¤ëŠ”ê²ƒ ì„ ì•Œ ìˆ˜ ìˆë‹¤ 
  ![image](https://user-images.githubusercontent.com/76824611/179300586-5eb6e7d9-1a1f-4b0b-b9dd-dcd46fe4a471.png)
* **ë¡œê·¸ìŒì„ í˜•ëª¨ë¸(Log-bilinear model)**       
  * ì´ëŸ¬í•œ ë™ì‹œë°œìƒí™•ë¥ ì˜ ë¹„ìœ¨ì„ ì„ í˜• ì˜ë¯¸êµ¬ì„±ìš”ì†Œë¡œ í¬ì°©í•˜ëŠ” ë°©ë²•    
  * $$w_i$$, $$w_j$$: ê°ê°ì˜ ì„ í˜• ìŒ      
  * $$w_a - w_b$$: ë‘ ë²¡í„°ì˜ ì°¨ì´    
  ![image](https://user-images.githubusercontent.com/76824611/179300916-e9035b97-0ab3-4cd1-8ff1-913b021d10d0.png)




**[Combining the best of both worlds GloVe]**     
* $$f(X_{ij})$$: ë†’ì€ ë¹ˆë„ì˜ ë‹¨ì–´ ìˆ˜ ì œí•œ    
* $$b$$: í¸í–¥         
* $$j$$: ë™ì‹œë°œìƒí–‰ë ¬ì—ì„œ countì‘ì—… ìµœì í™” ê¸°ëŠ¥         
![image](https://user-images.githubusercontent.com/76824611/179302510-2da2bc9e-84ae-45ff-8816-350302576266.png)
* **íŠ¹ì§•**     
   * Fast training    
   * Scalable to huge corpora    
   * Good performance even with small corpus and small vectors
   ![image](https://user-images.githubusercontent.com/76824611/179302639-da747452-29e9-4106-a03f-643ec06b7c0e.png)
* **ê²°ê³¼**    
![image](https://user-images.githubusercontent.com/76824611/179302750-0e4220ad-a6df-4e79-b42e-f5cc4a7796ee.png)


-----

## evaluate word vectors    
ê·¸ëŸ¼ ì´ ë‹¨ì–´ ë²¡í„°ë“¤ì´ ì˜ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í‰ê°€í•˜ëŠ” ë°©ë²•ë“¤ì„ ì•Œì•„ë³´ê² ë‹¤.     
ëŒ€í‘œì ìœ¼ë¡œ 2ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤.     
* **Intrinsic:** ë‚´ì       
* **Extrinsic:** ì™¸ì      


----


### Intrinsic

**[íŠ¹ì§•]**
* íŠ¹ì •/ì¤‘ê°„ í•˜ìœ„ ì‘ì—…ì—ì„œì˜ í‰ê°€    
* ê³„ì‚° ì†ë„ í–¥ìƒ   
* ì‹œìŠ¤í…œì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë¨    
* ì‹¤ì œ ì‘ì—…ì— ëŒ€í•œ ìƒê´€ê´€ê³„ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ”ì§€ ëª…í™•í•˜ì§€ ì•ŠìŒ      


**[ë°©ë²•: Word Vector Analogies]**         
* **í‰ê°€ ë°©ë²•**: ë‹¨ì–´ ë²¡í„°ë¥¼ ì¶”ê°€ í›„ ì½”ì‚¬ì¸ ê±°ë¦¬ê°€ ì§ê´€ì ì¸ ì˜ë¯¸ë¡ ì  ë° êµ¬ë¬¸ì  ìœ ì‚¬ ì§ˆë¬¸ì„ ì–¼ë§ˆë‚˜ ì˜ í¬ì°©í•˜ëŠ”ì§€ë¡œ í‰ê°€    
* ex) ```man:woman :: king:?``` â¡ Queenì´ë€ ë‹µì„ ë„ì¶œí•´ì•¼í•¨    
![image](https://user-images.githubusercontent.com/76824611/179303950-c97413ab-880c-46d1-9495-6bc25b46b1ae.png)
![image](https://user-images.githubusercontent.com/76824611/179303989-96a55a58-a5bd-4ad5-acb2-f731396c838e.png)
* **ë¬¸ì œ**: ë§Œì•½ ì •ë³´ê°€ ê±°ê¸°ì— ìˆì§€ë§Œ ì„ í˜•ì ì´ì§€ ì•Šë‹¤ë©´ ë¬¸ì œê°€ ëœë‹¤.       

<details>
<summary>ğŸ“œ Glove í‰ê°€ ë³´ê¸°</summary>
<div markdown="1">
![image](https://user-images.githubusercontent.com/76824611/179304122-84b57381-3f39-4757-9f16-5dbd20f0d2e9.png)
![image](https://user-images.githubusercontent.com/76824611/179304137-ce6cbfdd-6b66-4750-9636-bee50dc73a11.png)
![image](https://user-images.githubusercontent.com/76824611/179304162-69c4c45e-08d7-468e-a50a-c82b6196ef2b.png)
![image](https://user-images.githubusercontent.com/76824611/179304181-6ea59d4d-f145-4cd1-989c-13060e507b7d.png)
![image](https://user-images.githubusercontent.com/76824611/179304236-4a43c063-8ce2-4b75-a822-2345a24d5aab.png)

  
</div>
</details>  

<details>
<summary>ğŸ“œ ì¶”ê°€ Intrinsic ë³´ê¸°</summary>
<div markdown="1">
![image](https://user-images.githubusercontent.com/76824611/179304332-89b6c646-a646-42e0-959b-744d8bf6bdb7.png)
![image](https://user-images.githubusercontent.com/76824611/179304349-dd0b0ccc-726a-4b68-9d3b-1d3356dd2277.png)
![image](https://user-images.githubusercontent.com/76824611/179304388-61ed39bf-65e5-4d79-a228-d6961530d220.png)

  
</div>
</details>  


-----


### Extrinsic
* ì‹¤ì œ ì‘ì—…ì— ëŒ€í•œ í‰ê°€       
* ì •í™•ì„±ì„ ê³„ì‚°í•˜ëŠ” ë° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ   
* í•˜ìœ„ ì‹œìŠ¤í…œì´ ë¬¸ì œì¸ì§€ ìƒí˜¸ ì‘ìš©ì¸ì§€ ë˜ëŠ” ë‹¤ë¥¸ í•˜ìœ„ ì‹œìŠ¤í…œì¸ì§€ ë¶ˆë¶„ëª…í•¨    
* ì •í™•íˆ í•˜ë‚˜ì˜ ì„œë¸Œì‹œìŠ¤í…œì„ ë‹¤ë¥¸ ì„œë¸Œì‹œìŠ¤í…œìœ¼ë¡œ êµì²´í•˜ë©´ ì •í™•ë„ê°€ í–¥ìƒë¨ Â» Winning!     


**[ë°©ë²•: named entity recognition]**    
* ê°œì¸, ì¡°ì§ ë˜ëŠ” ìœ„ì¹˜ì— ëŒ€í•œ ì°¸ì¡° ì‹ë³„: Chris Manningì€ Palo Altoì— ì‚°ë‹¤   
![image](https://user-images.githubusercontent.com/76824611/179304578-5dde2b13-93f3-439d-95ec-0346b796f753.png)




-----
-----


# **Word senses and word sense ambiguity**     
**ë‹¨ì–´ ì˜ë¯¸ì˜ ëª¨í˜¸ì„± ë¬¸ì œ**: í•œ ë‹¨ì–´ê°€ ì—¬ëŸ¬ê°œì˜ ì˜ë¯¸ë¥¼ ê°–ì„ ìˆ˜ ìˆë‹¤.       
* íŠ¹íˆ í”í•œë‹¨ì–´ì—ì„œ ë§ì´ ë‚˜íƒ€ë‚¨    
* íŠ¹íˆ ì¡´ì¬í•œì§€ ì˜¤ë˜ëœ ë‹¨ì–´ì—ì„œ ë§ì´ ë‚˜íƒ€ë‚¨      

**[Example: pike]**    
* ì´ ë‹¨ì–´ëŠ” ì•„ë˜ì˜ ëª¨ë“  ì˜ë¯¸ë¥¼ ê°–ê³ ìˆìŒ    
  * A sharp point or staff
  * A type of elongated fish
  * A railroad line or system
  * A type of road
  * The future (coming down the pike)
  * A type of body position (as in diving)
  * To kill or pierce with a pike
  * To make oneâ€™s way (pike along)
  * In Australian English, pike means to pull out from doing something: I reckon he could have climbed that cliff, but he piked!   

ì¦‰ ìœ„ì˜ ê°„ì–´ì˜ ì˜ë¯¸ì— ëŒ€í•´ ê°™ì€ ë²¡í„°ê°€ ì•„ë‹Œ ê° ì˜ë¯¸ë§ˆë‹¤ ë‹¤ë¥¸ ë²¡í„°ë¥¼ ê°–ëŠ”ê²ƒì´ ëª©í‘œì´ë‹¤. 

**[SOLUTION 1: Improving Word Representations Via Global Context And Multiple Word Prototypes (Huang et al. 2012)]**     
* ë‹¨ì–´ë¥¼ í•™ìŠµì‹œí‚¤ê³  êµ°ì§‘ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ìœ„ì¹˜ëœ ê°™ì€ ë‹¨ì–´ëŠ” ë”°ë¡œ ë²¡í„°ë¥¼ ë¶€ì—¬í•˜ê³  ë”°ë¡œí•™ìŠµì‹œí‚´       
* ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ì— ìˆëŠ” ê°™ì€ ë‹¨ì–´ëŠ” ë‹¤ë¥¸ë‹¨ì–´ ì·¨ê¸‰í•˜ëŠ” ê²ƒ      
* í•˜ì§€ë§Œ ë§ë­‰ì¹˜ë§ˆë‹¤ í¸ì°¨ê°€ í¬ê²Œ í•™ìŠµëœë‹¤ëŠ” ë‹¨ì ì´ ìˆìŒ    
![image](https://user-images.githubusercontent.com/76824611/179307513-f6d93138-5881-4a14-b3ad-5ad2683adf9a.png)



**[SOLUTION 2: Linear Algebraic Structure of Word Senses, with Applications to Polysemy]**    
* ë‹¤ë¥¸ ë‹¨ì–´ëŠ” ë”°ë¡œ ë²¡í„°ë¥¼ ë§Œë“¤ì–´ í•™ìŠµì‹œí‚¤ê³  ì•„ë˜ì™€ ê°™ì´ ì´ì— ëŒ€í•œ í‰ê· ì„ ëƒ„     
![image](https://user-images.githubusercontent.com/76824611/179307724-e0e18fb9-a9cd-4494-a052-393f2ec7205a.png)
* í•˜ì§€ë§Œ ì´ëŸ¬í•œ í‰ê· ì€ ë”ìš± í° ëª¨í˜¸ì„±ì„ ê°–ê³ ì˜¬ ìˆ˜ ìˆë‹¤ëŠ” ë‹¨ì ì´ ìˆìŒ    
* ê·¸ëŸ¼ì—ë„ ì•„ë˜ì™€ ê°™ì´ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ê¸´ í•¨    
![image](https://user-images.githubusercontent.com/76824611/179307759-8c72e140-6b9e-4649-9c17-d7e89bebc5b8.png)



