---
title: "FastText: Bag of Tricks for Efficient Text Classification ì •ë¦¬"
date:   2022-11-10
excerpt: "Bag of Tricks for Efficient Text Classification"
category: [Paper]
layout: post
tag:
- Paper
order: 0

comments: true
---




# **ëª©ì°¨**    
- [**intro**](#intro)
- [**Abstract**](#abstract)
- [**1. Introduction**](#1--introduction)
- [**2. Model architecture**](#2-model-architecture)
  * [2.1 Hierarchical softmax](#21-hierarchical-softmax)
  * [2.2 N-gram features](#22-n-gram-features)
- [**3. Experiments**](#3-experiments)
  * [3.1  Sentiment analysis](#31--sentiment-analysis)
  * [3.2 Tag prediction](#32-tag-prediction)

---

# **intro**
 
      


## ì½ê¸° ìœ„í•´ í•„ìš”í•œ ì§€ì‹
* [word2vec](https://yerimoh.github.io/DL14/): baseline ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— ê¼­ ì•Œì•„ì•¼ í•œë‹¤.        
* [Embedding](https://yerimoh.github.io/DL15/): word2vec ì†ë„ ê°œì„ ìœ¼ë¡œ ì´ í¬ìŠ¤íŒ…ë„ ê¼­ ì•Œì•„ì•¼ í•œë‹¤.      

## ì› ë…¼ë¬¸
[Bag of Tricks for Efficient Text Classification](https://arxiv.org/pdf/1607.01759.pdf)



---

# **Abstract**
ì´ ë…¼ë¬¸ì€ text classificationë¥¼ ìœ„í•œ ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ì¸ baselineì„ íƒêµ¬í•œë‹¤.      
ìš°ë¦¬ì˜ ì‹¤í—˜ì€ [fastText](https://yerimoh.github.io/LAN7/)ê°€ accuracy ì¸¡ë©´ì—ì„œ ë”¥ ëŸ¬ë‹ classifiersì™€ ë™ë“±í•˜ì§€ë§Œ, í›ˆë ¨ê³¼ í‰ê°€ì—ì„  ì´ ëª¨ë¸ì´ ëª‡ ë°°ë‚˜ ë” ë¹ ë¥´ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.      

ì´ ë…¼ë¬¸ì€ standard multicore CPUë¥¼ ì‚¬ìš©í•˜ì—¬ 10ë¶„ ì´ë‚´ì— 10ì–µ ê°œ ì´ìƒì˜ ë‹¨ì–´ì— ëŒ€í•´ì„œ **ë¹ ë¥´ê²Œ í…ìŠ¤íŠ¸ë¥¼ train**í•  ìˆ˜ ìˆê³ , 312K í´ë˜ìŠ¤ ì¤‘ 50ë§Œ ê°œì˜ ë¬¸ì¥ì„ 1ë¶„ ì´ë‚´ì— ë¶„ë¥˜í•  ìˆ˜ ìˆë‹¤.   

âœ¨ **ì¦‰ ë¹ ë¥´ê²Œ trainí•˜ë©° ë¹ ë¥´ê²Œ ë¶„ë¥˜ê°€ ê°€ëŠ¥í•œ ëª¨ë¸ì„ ë§Œë“¤ì–´ ëƒˆë‹¤**ëŠ” ê²ƒì´ë‹¤ âœ¨ 


![image](https://user-images.githubusercontent.com/76824611/211566345-debe1927-40eb-4011-855e-6196fe154657.png)


---


# **1. Introduction**

**[ê¸°ì¡´ ëª¨ë¸ë“¤ì˜ ë¬¸ì œ]**    
* í…ìŠ¤íŠ¸ ë¶„ë¥˜ëŠ” ì›¹ ê²€ìƒ‰, ì •ë³´ ê²€ìƒ‰, ìˆœìœ„ ë° ë¬¸ì„œ ë¶„ë¥˜ì™€ ê°™ì€ ë§ì€ ì‘ìš© í”„ë¡œê·¸ë¨ì´ ìˆëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì¤‘ìš”í•œ ì‘ì—…ì´ë‹¤.  
ë˜í•œ ì´ëŠ” 14ë„ë¶€í„° ì‹ ê²½ë§ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ëª¨ë¸ì´ ì ì  ë” ì¸ê¸°ë¥¼ ëŒê³  ìˆë‹¤.    
â¡ ì´ëŸ¬í•œ ëª¨ë¸ì€ ì‹¤ì œë¡œ ë§¤ìš° ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì§€ë§Œ,     
**í›ˆë ¨ê³¼ í…ŒìŠ¤íŠ¸ ì‹œê°„ ëª¨ë‘ì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦° ê²½í–¥**ì´ ìˆì–´ ë§¤ìš° í° ë°ì´í„° ì„¸íŠ¸ì—ì„œì˜ ì‚¬ìš©ì—” í•œê³„ê°€ ì¡´ì¬í•œë‹¤.     


**[linear classifiersì˜ ì ì¬ë ¥]**        
* [linear classifiers](https://en.wikipedia.org/wiki/Linear_classifier)ëŠ” í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë¬¸ì œì˜ ê°•ë ¥í•œ baselinesìœ¼ë¡œ ê°„ì£¼ëœë‹¤.     
ì´ê²ƒì€ ë‹¨ìˆœí•˜ì§€ë§Œ ì ì ˆí•˜ê²Œ ì‚¬ìš©í•˜ë©´ stateof-the-art ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.              
ë˜í•œ **ë§¤ìš° í° ë§ë­‰ì¹˜ë¡œ í™•ì¥í•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥**ë„ ê°€ì§€ê³  ìˆë‹¤.       




**[linear classifiersë¥¼ ëª¨ë¸ì— ì ìš©]**    
* ë³¸ ë…¼ë¬¸ì€ í…ìŠ¤íŠ¸ ë¶„ë¥˜ì˜ ë§¥ë½ì—ì„œ ì´ëŸ¬í•œ baselinesì„ **large output spaceì„ ê°€ì§„ ë§¤ìš° í° ë§ë­‰ì¹˜ë¡œ í™•ì¥**í•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•œë‹¤.      
* [Word2vec](https://arxiv.org/abs/1301.3781)ì˜ ì—°êµ¬ì—ì„œ ì˜ê°ì„ ë°›ì•„,   
rank ì œì•½ê³¼ ë¹ ë¥¸ loss ê·¼ì‚¬ë¥¼ ê°€ì§„ **linear modelsì´ 10ë¶„ ì´ë‚´ì— 10ì–µ ë‹¨ì–´ì— ëŒ€í•´ í›ˆë ¨í•  ìˆ˜ ìˆëŠ” ë™ì‹œì— ìµœì²¨ë‹¨ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤**.       
* evaluation: ìš°ë¦¬ëŠ” íƒœê·¸ ì˜ˆì¸¡ê³¼ ê°ì • ë¶„ì„ì´ë¼ëŠ” ë‘ ê°€ì§€ ë‹¤ë¥¸ ì‘ì—…ì—ì„œ [fastText](https://github.com/facebookresearch/fastText) ì ‘ê·¼ ë°©ì‹ì˜ í’ˆì§ˆì„ í‰ê°€í•œë‹¤.           




----
----


# **2. Model architecture**


**[linear classifiersì˜ ì‚¬ìš©]**     
* ë¬¸ì¥ ë¶„ë¥˜ë¥¼ ìœ„í•œ ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ì¸ ê¸°ì¤€ì€ ë¬¸ì¥ì„ [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model) (BoW) ìœ¼ë¡œ í‘œí˜„í•˜ê³ ,     
linear classifier(ì˜ˆ: logistic regression ë˜ëŠ” [SVM](https://yerimoh.github.io/ML3/)ë¥¼ í›ˆë ¨í•˜ëŠ” ê²ƒì´ë‹¤.      


**[linear classifiersì˜ ê°œì„ ]**     
* ê·¸ëŸ¬ë‚˜ linear classifiersëŠ” **features ë° class ê°„ì— ë§¤ê°œ ë³€ìˆ˜ë¥¼ ê³µìœ í•˜ì§€ ì•ŠëŠ”ë‹¤**.      
* ì´ëŠ” **ì˜ˆì œê°€ ê±°ì˜ ì—†ëŠ” large output spaceì—ì„œ ì¼ë°˜í™”ë¥¼ ì œí•œ**í•  ìˆ˜ ìˆë‹¤.      
â¡ ì´ ë¬¸ì œì— ëŒ€í•œ ì¼ë°˜ì ì¸ í•´ê²°ì±…ì€ linear classifierë¥¼ **low rank matricesë¡œ ë¶„í•´**í•˜ê±°ë‚˜ **ë‹¤ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©**í•˜ëŠ” ê²ƒì´ë‹¤.   




**[ëª¨ë¸ êµ¬ì„±]**   
ë³¸ ë…¼ë¬¸ì˜ ëª¨ë¸ì€ ì•„ë˜ì™€ ê°™ë‹¤.
ì´ëŠ” rank ì œì•½ ì¡°ê±´ì´ ìˆëŠ” simple linear modelì„ ë³´ì—¬ì¤€ë‹¤.     

<img width="323" alt="image" src="https://user-images.githubusercontent.com/76824611/210780968-f9457e60-d22b-4410-889b-36e5ab4f57fe.png">  
[Figure 1] Ngramì˜ features($$x_1, . ., x_N$$)ì´ ìˆëŠ” ë¬¸ì¥ì— ëŒ€í•œ fastText ëª¨ë¸ ì•„í‚¤í…ì²˜    
featuresë“¤ì€ hidden variableë¥¼ í˜•ì„±í•˜ê¸° ìœ„í•´ embeddedë˜ê³  í‰ê· í™”ëœë‹¤. 


1ï¸âƒ£ ì²« ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ AëŠ” ë‹¨ì–´ ìœ„ì˜ look-up tableì´ë‹¤.       
2ï¸âƒ£ ê·¸ëŸ° ë‹¤ìŒ ë‹¨ì–´ í‘œí˜„ì€ text representationìœ¼ë¡œ í‰ê· í™”ëœë‹¤.             
3ï¸âƒ£ text representationì€ linear classifierì— ì…ë ¥ëœë‹¤.      
â€» text representationì€ ì ì¬ì ìœ¼ë¡œ ì¬ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” hidden variableì…ë‹ˆë‹¤.     


<details>
<summary>ğŸ“œ look-up tableì´ë€? </summary>
<div markdown="1">
 
 
Embedding ë ˆì´ì–´ëŠ” **ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ ë‹¨ì–´ë¥¼ ë¶„ì‚° í‘œí˜„ìœ¼ë¡œ ì—°ê²°í•´ ì£¼ëŠ” ì—­í• **ì„ í•˜ëŠ”ë°,     
ê·¸ê²ƒì´ **Weightì—ì„œ íŠ¹ì • í–‰ì„ ì½ì–´ì˜¤ëŠ” ê²ƒê³¼ ê°™ì•„** **ì´ ë ˆì´ì–´ë¥¼ ë£©ì—… í…Œì´ë¸”(Lookup Table)**ì´ë¼ê³  ë¶€ë¥´ê¸°ë„ í•©ë‹ˆë‹¤.   
 
ì´ê²Œ ë¬´ìŠ¨ ì†Œë¦¬ëƒë©´, 
ì„ë² ë”© ì¸µì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ **ê° ë‹¨ì–´ë“¤ì€ ëª¨ë‘ ì •ìˆ˜ ì¸ì½”ë”©**ì´ ë˜ì–´ìˆì–´ì•¼ í•œë‹¤.       

íŠ¹ì • ë‹¨ì–´ì™€ ë§µí•‘ë˜ëŠ” ì •ìˆ˜ë¥¼ ì¸ë±ìŠ¤ë¡œ ê°€ì§€ëŠ” í…Œì´ë¸”ë¡œë¶€í„° **ì„ë² ë”© ë²¡í„° ê°’ì„ ê°€ì ¸ì˜¤ëŠ” ë£©ì—… í…Œì´ë¸”ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.**    
![image](https://user-images.githubusercontent.com/76824611/210789841-ddb0d5c9-212d-4459-a8b5-4b92a17a8c29.png)
![image](https://user-images.githubusercontent.com/76824611/210788684-7cfd8297-99ea-4ac3-8d2f-57077702f69f.png)

ì´í•´ê°€ ì•ˆë˜ë‹¤ë©´ ì´ ë…¼ë¬¸ì˜ ê¸°ë°˜ ë…¼ë¬¸ì¸ [Word2vec](https://yerimoh.github.io/DL14/)ë¥¼ ì œëŒ€ë¡œ ì•Œê³ ì˜¤ì.   

</div>
</details>


ì´ ì•„í‚¤í…ì²˜ëŠ” ì¤‘ê°„ ë‹¨ì–´ê°€ ë ˆì´ë¸”ë¡œ ëŒ€ì²´ë˜ëŠ” [cbow ëª¨ë¸](https://yerimoh.github.io/DL14/#cbow-%EB%AA%A8%EB%8D%B8)ê³¼ ìœ ì‚¬í•˜ë‹¤.      
[ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜](https://yerimoh.github.io/DL2/#%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4-%ED%95%A8%EC%88%98-softmax-function) $$f$$ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ ì •ì˜ëœ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ê³„ì‚°í•œë‹¤.       
Nê°œì˜ ë¬¸ì„œ ì§‘í•©ì˜ ê²½ìš°, ì´ê²ƒì€ í´ë˜ìŠ¤ì— ëŒ€í•œ negative loglikelihoodë¥¼ ìµœì†Œí™”í•œë‹¤.     



![image](https://user-images.githubusercontent.com/76824611/211345393-5292f937-1ffb-499a-9c27-8157a1774a16.png)
* ì—¬ê¸°ì„œ $$x_n$$ì€ në²ˆì§¸ documentì˜ ì •ê·œí™”ëœ bag of featuresì´ë‹¤.     
* $$y_n the label$$ Aì™€ Bì˜  weight matricesì´ë‹¤.        
* ì´ model ì€ [stochastic gradient descent](https://yerimoh.github.io/DL5/#%ED%99%95%EB%A5%A0%EC%A0%81-%EA%B2%BD%EC%82%AC-%ED%95%98%EA%B0%95%EB%B2%95-sgd)ì™€ linearly decaying learning rateë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ CPUì—ì„œ ë¹„ë™ê¸°ì‹ìœ¼ë¡œ í›ˆë ¨ëœë‹¤.












<details>
<summary>ğŸ“œ Negative Log-Likelihood (NLL) ë³´ê¸°</summary>
<div markdown="1">

ì‹¤ì œ softmaxì„ ì“¸ ë•ŒëŠ” negative log-likelihood(NLL)ì™€ ì‚¬ìš©ëœë‹¤.     

<img width="224" alt="image" src="https://user-images.githubusercontent.com/76824611/210790935-eb6ad9f7-dc6a-4ab0-8aca-4fc8ec44b626.png">

ì¦‰, ë¹„ìœ ë¥¼ í•˜ìë©´ ì†Œí”„íŠ¸ë§¥ìŠ¤í•¨ìˆ˜ëŠ” í–‰ë³µì§€ìˆ˜ë¥¼ ì°¾ëŠ” ê²ƒì´ë¼ë©´,      
Negative Log-Likelihood (NLL)ëŠ” ë¶ˆí–‰ì§€ìˆ˜ë¥¼ ì°¾ëŠ”ê²ƒì´ë‹¤.     

Negative Log-Likelihood (NLL)ì€ ì•„ë˜ì™€ ê°™ì€ë°,   
inputì´ 0ì¼ ë•Œ ë¬´í•œìœ¼ë¡œ ê°€ê³ , inputì´ 1ì¼ ë•Œ 0ìœ¼ë¡œ ê°„ë‹¤.     
![image](https://user-images.githubusercontent.com/76824611/210791528-7e2f0770-0c33-4377-ab4a-3c505efe13e4.png)

ì¦‰ ì •ë¦¬í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ì€ ê´€ê³„ë¥¼ ê°–ëŠ”ë‹¤.   
![image](https://user-images.githubusercontent.com/76824611/210791835-8d044c5e-e3f7-43c5-8ab8-27ce3200cb5d.png)

lossë¥¼ ê³„ì‚°í•  ë•Œ ìš°ë¦¬ëŠ” ì •ë‹µ classì— ëŒ€í•œ ë†’ì€ í™•ë¥ ì€ ë‚®ì€ lossë¡œ ì´ì–´ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.           


</div>
</details>  


---


## 2.1 Hierarchical softmax


Hierarchical Softmaxì€ [negative sampling](https://yerimoh.github.io/DL15/#2--%EB%84%A4%EA%B1%B0%ED%8B%B0%EB%B8%8C-%EC%83%98%ED%94%8C%EB%A7%81%EC%9D%B4%EB%9E%80-%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98-%EB%8F%84%EC%9E%85)ê³¼ ê°™ì´ ì—°ì‚°ì´ ë„ˆë¬´ ë¹„ëŒ€í•´ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ê³ ì•ˆëœ ë°©ì‹ì´ë‹¤.     

ì¦‰ í•œë§ˆë””ë¡œ ìš”ì•½í•˜ìë©´ Hierarchical Softmax ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ **ë°±í„°ì˜ ë‚´ì ì„ ì´ì§„ ë¶„ë¥˜ë¡œ ë°”ê¿” ê³„ì‚°ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤**ëŠ” ê²ƒì´ë‹¤.    
â¡ 100ë§Œê°œì˜ ë‹¨ì–´ë¥¼ ë²¡í„°ì˜ ë‚´ì ìœ¼ë¡œ êµ¬í•˜ë©´ ë²¡í„°ì˜ ë‚´ì ì„ 100ë§Œë²ˆ í•´ì•¼í•˜ì§€ë§Œ,       
 Hierarchical Softmax ë°©ë²•ì„ í†µí•œ ì´ì§„ë¶„ë¥˜ë¡œ êµ¬í•˜ë©´ $$log_2(100ë§Œ)$$ ì•½ 19ë²ˆë§Œ ê³„ì‚°í•˜ë©´ ë˜ëŠ” ê²ƒì´ë‹¤.     
 
ê·¸ë ‡ë‹¤ë©´ ì–´ë–»ê²Œ ì´ì™€ ê°™ì´ ì´ì§„ë¶„ë¥˜ë¡œ ê³„ì‚°í•˜ëŠ”ì§€ ì•Œì•„ë³´ê² ë‹¤.    


### ì˜ˆì‹œ   
ì´ëŠ” ëª¨ë¸ êµ¬ì¡° ìì²´ë¥¼ [full binary tree](https://yerimoh.github.io/Algo022/#%EC%9D%B4%EC%A7%84-%ED%8A%B8%EB%A6%AC-%EC%9C%A0%ED%98%95-types-of-binary-trees) êµ¬ì¡°ë¡œ ë°”ê¾¼ í›„ì— ë‹¨ì–´ë“¤ì€ [leaf node](https://yerimoh.github.io/Algo022/#%ED%8A%B8%EB%A6%AC%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90)ì— ë°°ì¹˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë¶€í„° ì‹œì‘ëœë‹¤.


ì˜ˆë¥¼ ë“¤ì–´ì„œ ì„¤ëª…í•´ë³´ê² ë‹¤.
ì•„ë˜ì™€ ê°™ì€ ë¬¸ì¥(Context)ê°€ ìˆë‹¤ê³  í•´ë³´ì.   

ê·¸ë ‡ë‹¤ë©´ ì´ ë¬¸ì¥ì—ì„œ **'to'** ë¼ëŠ” ì¤‘ì‹¬ë‹¨ì–´ë¥¼, window size = 1ì— í•´ë‹¹í•˜ëŠ” ì£¼ë³€ë‹¨ì–´ **(want, eat)** ë“¤ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•œë‹¤ê³  ê°€ì •í•˜ì.    

ê·¸ë ‡ë‹¤ë©´ ì•„ë˜ì™€ ê°™ì€ treeì—ì„œ í•™ìŠµì´ ë  ê²ƒì´ë‹¤.     
í¸ì˜ë¥¼ ìœ„í•´ wantì™€ eatì¤‘ **want**ë¡œ ë§Œ ë¥¼ ì˜ˆì‹œë¡œ ë“¤ì—ˆë‹¤.


 
ì—¬ê¸°ì„œ ìµœì¢… í™•ë¥ (ì¶œë ¥ì¸µì˜ ê°’)ì€ rootë¶€í„° leafê¹Œì§€ ê°€ëŠ” ê¸¸ì— ìˆëŠ” í™•ë¥ ì„ ëª¨ë‘ ê³±í•˜ì—¬ ê³„ì‚°ëœë‹¤.     
ë” ë†’ì€ í™•ë¥ ì˜ edgeë¥¼ ì„ íƒí•´ë‚˜ê°„ë‹¤.    
ê·¸ë¦¬ê³  ì•„ë˜ì—ì„œ ë³´ë‹¤ì‹œí”¼ ê° edgeì˜ í•©ì€ 1ì´ë‹¤.(í™•ë¥ )(ë˜‘ê°™ì€ ìƒ‰ì˜ í•©ì€ 1ì´ë‹¤)    
ì¦‰ Iê°€ ë‚˜ì˜¬ í™•ë¥ ì„ ê³„ì‚°í•´ë³´ë©´, **$$0.7$$ x $$0.8$$ x $$0.6$$** ì´ë‹¤.    

![image](https://user-images.githubusercontent.com/76824611/210959022-df840eb3-0892-4637-84f8-bf47411e93c6.png)


ì¦‰ ìœ„ì˜ ë°©ë²•ë“¤ì„ í†µí•´ Hierarchical SoftmaxëŠ” ì¶œë ¥ì¸µì˜ ê°’ì„ softmax í•¨ìˆ˜ë¡œ ì–»ëŠ” ê²ƒ ëŒ€ì‹ ì— binatr treeë¥¼ ì´ìš©í•˜ì—¬ ì–»ëŠ” ê²ƒì´ë‹¤.        


### ì¼ë°˜í™”    
ê·¸ë ‡ë‹¤ë©´ ìœ„ì˜ ì‹ë“¤ì„ ì¼ë°˜í™”í•´ë³´ì.    
ì¼ë°˜í™”í•œ ë…¸ë“œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.     
![image](https://user-images.githubusercontent.com/76824611/210958934-b07bbb8f-6b76-4a12-9c6e-12dd8a26c5a6.png)

ê° ë‹¨ì–´ê°€ output wordê°€ ë  í™•ë¥ ì˜ ì‹ì€ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.    

<img width="404" alt="image" src="https://user-images.githubusercontent.com/76824611/211276759-6c6f95e1-7ecd-42ef-b647-db48ebd8da48.png">

* **$$n()$$**: node    
* **$$L(w)$$**:leafê¹Œì§€ì˜ childern nodeì˜ ìˆ˜    
* **$$ch(n(w,i))$$** : $$ch(n(w,i))$$ì˜ ìì‹ ë…¸ë“œ ì¤‘ í•œ ìª½ (í•­ìƒ ì™¼ìª½ë…¸ë“œê±°ë‚˜ ì˜¤ë¥¸ìª½ ë…¸ë“œë¥¼ ëœ»í•¨)     
  * **$$n(w,i)$$**: $$w$$ì˜ leafê¹Œì§€ ê°€ëŠ” $$i$$ë²ˆì§¸ child node    
  * **$$n(w, L(w))$$**: leaf node     
* **$$\begin{Vmatrix}x \end{Vmatrix}$$**    
  * **xê°€ ì°¸ì´ë©´ 1:** ì¦‰, $$ch(n(w,i))$$ê°€ í•­ìƒ ì™¼ìª½ë…¸ë“œë¥¼ ëœ»í•  ë•Œ ê°€ì•¼í•  ì™¼ìª½ì´ë©´ 1(ì™¼ìª½ìœ¼ë¡œ ê°€ì•¼í•˜ë©´ 1)         
  * **xê°€ ê±°ì§“ì´ë©´ -1:** ì¦‰, $$ch(n(w,i))$$ê°€ í•­ìƒ ì™¼ìª½ë…¸ë“œë¥¼ ëœ»í•  ë•Œ ê°€ì•¼ ë…¸ë“œê°€ ì˜¤ë¥¸ìª½ì´ë©´ -1(ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê°€ì•¼í•˜ë©´ -1)        
* **$$ğœ$$**:  $$= 1 \over 1+e^{-x}$$: ì¦‰ ì‹œê·¸ëª¨ì´ì¦ˆ í•¨ìˆ˜ì´ë‹¤.       


**[ì‹ í•´ì„]**    
* ë¨¼ì € **$$n(w,j+1) = ch(n(w,j))$$** ì˜ ì˜ë¯¸ë¥¼ ì‚´í´ë³´ì.              
ê·¸ë ‡ë‹¤ë©´ ìš°ë¦¬ëŠ” $$ch(n(w,j))$$ê°€ ì™¼ìª½ ë…¸ë“œë¥¼ ëœ»í•œë‹¤ê³  í•´ë³´ì,       
ì¦‰ ì´ëŠ” $$n(w,j+1)$$ê°€ $$\begin{Vmatrix}x \end{Vmatrix}$$ì— ì˜í•´ ì™¼ìª½ë…¸ë“œì´ë©´ 1, ì˜¤ë¥¸ìª½ ë…¸ë“œì´ë©´ -1ì´ ëœë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.     
â€» $$ch(n(w,i))$$ëŠ”  $$n(w,i)$$ì˜ ìì‹ë…¸ë“œ ì¤‘ í•˜ë‚˜ë¥¼ ì·¨í•˜ë©´ì„œ ë‚˜ê°„ë‹¤(ì™¼ìª½ or ì˜¤ë¥¸ìª½ ìì‹ë…¸ë“œë¥¼ ì„ íƒí•˜ë©° ë‚˜ê°)     

* ì´ë ‡ê²Œ ëœë‹¤ë©´, **$$ğœ(x) + ğœ(-x) = 1$$** ì´ë¼ëŠ” sigmoid functionì˜ íŠ¹ì§•ìœ¼ë¡œ ì¸í•´ ì•„ë˜ì™€ ê°™ì€ ì‹ì´ ì„±ë¦½ëœë‹¤.    
  * $$p(n, left) = ğœ(ğ‘£â€²_{n}^{T} h)$$       
  * $$p(n, right) = 1 - ğœ(ğ‘£â€²_{n}^{T} h) = ğœ(- ğ‘£â€²_{n}^{T} h)$$      
â¡ ì¦‰, ì´ëŠ” ì•ì„œ ì–¸ê¸‰í•œ **ì´ë¶„ëœ ìì‹ ë…¸ë“œì˜ ë‘ í™•ë¥ ì˜ í•©ì´ 1**ì´ ëœë‹¤ëŠ” ê°€ì •ì„ í•­ìƒ ë§Œì¡±í•˜ê²Œëœë‹¤.     


* ê·¸ë¦¬ê³  ì´ hierarchical softmaxëŠ” $$\displaystyle\sum_{w=0}^{\|V|}{â„™(w|w_I)}$$ë¥¼ ë§Œì¡±í•œë‹¤.      
ì¦‰ $$|V|$$ê°œë¥¼ ëª¨ë‘ ê³„ì‚°í•˜ëŠ” ê²ƒ ë³´ë‹¤ ê³„ì‚°ëŸ‰ì´ ì¤„ì–´ë“ ë‹¤.    
ë˜í•œ ê° $$â„™$$ê°€ í™•ë¥ ì´ë¯€ë¡œ ê° ë…¸ë“œì˜ í™•ë¥ ì„ ê³±í•˜ëŠ” ê²ƒì´ë‹¤. ì¦‰ ê° ë‹¨ì–´ì˜ **í™•ë¥ ì´ ìµœì¢…ì ìœ¼ë¡œ í•©ì´ 1**ì´ë˜ëŠ” ì¶œë ¥ì¸µì„ ë„ì¶œ ê°€ëŠ¥í•˜ë‹¤.     
â€» $$|V|$$ ëŠ” ì „ì²´ ë‹¨ì–´ì˜ ê°œìˆ˜ì´ë‹¤. ì¦‰ output wordê°€ ìœ„ì˜ ì˜ˆì‹œì™€ ê°™ì´ 'I', 'want', 'to', 'eat', 'some', 'cake'ì´ë¼ë©´ $$|V|$$ = 6ì´ë‹¤.   


ì´ë¥¼ í† ëŒ€ë¡œ ìœ„ ê·¸ë¦¼ì—ì„œ $$w_2$$ê°€ ë‚˜ì˜¬ í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.    
<img width="424" alt="image" src="https://user-images.githubusercontent.com/76824611/211290571-1ac447e5-957f-4d01-ac50-51efd3a2992f.png">



ë”°ë¼ì„œ ië²ˆì§¸ vectorëŠ” í•™ìŠµì´ ì§„í–‰ë¨ì— ë”°ë¼ updateê°€ ë  ê²ƒì´ê³  ì´ì— ë”°ë¼ ë³µì¡í•œ ì—°ì‚°ì„ ë°°ì œí•  ìˆ˜ ìˆìœ¼ë©° ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•œ í•™ìŠµì´ $$log(V)$$ë¡œ ì¤„ì–´ë“ ë‹¤ëŠ” í° ì¥ì ì´ ìˆë‹¤.


---


## 2.2 N-gram features


**Bag of words**ëŠ” BOWëŠ” ë‹¨ì–´ì˜ ìˆœì„œ ë‹¨ì–´ë“¤ì„ ë‹´ëŠ” ê°€ë°©ìœ¼ë¡œ, ì•„ë˜ì™€ ê°™ì´ ë‹¨ì–´ë¥¼ ë‹´ëŠ”ë‹¤.    
ì´ëŠ” ë‹¨ì–´ ë°°ì—´ ìˆœì„œì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ì •ë³´ë“¤ì„ íŒŒì•…í•  ìˆ˜ ì—†ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.   

<center>sentence = 'I want to eat some cake'</center>       

<center>Bag of words = {'I', 'want', 'to', 'eat', 'some', 'cake'}</center>     

â€» ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìª¼ê°œ ê·¸ëƒ¥ ë„£ì€ ê²ƒì´ë¯€ë¡œ Bag of wordsì—ì„  ì´ ë‹¨ì–´ë“¤ ì‚¬ì´ì˜ ë°°ì—´ ì •ë³´ê°€ ì•„ì´ì— ì—†ë‹¤.


ì´ ë‹¨ì ì„ ë³´ì•ˆí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” local ë‹¨ì–´ ìˆœì„œì— ëŒ€í•œ ì¼ë¶€ ì •ë³´ë¥¼ ìº¡ì²˜í•˜ê¸° ìœ„í•œ ì¶”ê°€ ê¸°ëŠ¥ìœ¼ë¡œ **bag of n-grams**ë¥¼ ì‚¬ìš©í•œë‹¤.     
ì‚¬ìš© ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.(ì•„ë˜ ê²°ê³¼ëŠ” bi-gram ì¦‰ ë‹¨ì–´ 2ê°œ ë‹¨ìœ„ë¡œ ìª¼ê°œëŠ” ê²ƒìœ¼ë¡œ ì˜ˆì‹œë¥¼ ë“¤ì—ˆë‹¤.)     


<center>sentence = 'I want to eat some cake'</center>       

<center>Bag of words = {'[start] I', 'I want', 'want to', 'to eat', 'eat some', 'some cake'. 'cake [end]'}</center> 
 
ì´ëŠ” ê·¸ë˜ë„ ë‘ ë‹¨ì–´ ë³„ë¡œ ë¬¶ì–´ ì–‘ ì˜†ì˜ ë‹¨ì–´ì— ëŒ€í•´ì„œì˜ ìˆœì„œ ì •ë³´ë¥¼ ê°–ê³ ìˆë‹¤.    
ì´ ë°©ë²•ì€ ë‹¨ì–´ë¼ë¦¬ì˜ ìˆœì„œ ì •ë³´ë¥¼ ì•„ì´ì— ë‹´ì„ ìˆ˜ ì—†ëŠ” Bag of wordë³´ë‹¤ ë” ë§ì€ ì •ë³´ë¥¼ ë‹´ê³ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.      

ì´ëŠ” ìˆœì„œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ê³¼ ë¹„êµí•  ìˆ˜ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ìœ¼ë©´ì„œ **ì‹¤ì œë¡œ ë§¤ìš° íš¨ìœ¨ì **ì´ë‹¤. 



ë³¸ ë…¼ë¬¸ì€ ìœ„ì—ì„œ ì–¸ê¸‰í•œ **bigrams**ì„ ê¸°ë°˜ìœ¼ë¡œ Mikolov et al. (2011)ê³¼ ë™ì¼í•œ [hashing function](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/12/ASRU-2011.pdf)ê³¼ 10M binsì„ ì‚¬ìš©í•˜ì—¬ **n-gramì˜ ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë§¤í•‘ì„ ìœ ì§€**í•˜ê³ , bigramsì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ 100M binsì„ ì‚¬ìš©í•œë‹¤.




----
----


# **3. Experiments**

ë³¸ ë…¼ë¬¸ì—ì„  ë‘ê°€ì§€ taskë¡œ FastTextë¥¼ í‰ê°€í•œë‹¤.        
**[1]** sentiment analysisì™€ ê¸°ì¡´ text classiferì™€ ë¹„êµí•œë‹¤.        
**[2]** ê·¸ ë‹¤ìŒ, tag prediction datasetì—ì„œ large output spaceìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆëŠ” ìš©ëŸ‰ì„ í‰ê°€í•œë‹¤.      


ë³¸ ë…¼ë¬¸ì˜ ëª¨ë¸ì€ Wowpal Wabbit ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ êµ¬í˜„ë  ìˆ˜ ìˆì§€ë§Œ, ì‹¤ì œë¡œ ìš°ë¦¬ëŠ” ë§ì¶¤í˜• êµ¬í˜„ì´ ìµœì†Œ 2-5ë°° ë¹ ë¥´ë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤.     
 
 
----
 
## 3.1  Sentiment analysis
 
 
<img width="430" alt="image" src="https://user-images.githubusercontent.com/76824611/211336624-6db73f37-6ca5-4ff1-a962-ab465cbf068a.png">

**[setting]**      
* Test accuracy [%] on sentiment datasets     
* FastText has been run with the same parameters for all the datasets     
* **10 hidden units** and we evaluate it **with** and** without bigrams**     
* **learning rate** selected on a validation set from {0.05, 0.1, 0.25, 0.5}         
* Training time for a **single epoch** on sentiment analysis datasets compared to char-CNN and VDCNN.   
 
 
 
**[Results]**   
* bigram information improves the performance by 1-4%.     
* ì´ ëª¨ë¸ì€ char-CNN and char-CRNNë³´ë‹¨ ì •í™•ë„ê°€ ì•½ê°„ ë†’ì§€ë§Œ VDCNNë³´ë‹¨ ì„±ëŠ¥ì´ ë‚®ë‹¤.       
* n-gramsì„ ì‚¬ìš©í•˜ë©´ ì •í™•ë„ë¥¼ ì¡°ê¸ˆ ì˜¬ë¦´ ìˆ˜ ìˆë‹¤(eg, trigramsì€ Sogouì—ì„œ 97.1%ê¹Œì§€ ì˜¬ë¼ê°”ë‹¤.)       
 

 
<img width="209" alt="image" src="https://user-images.githubusercontent.com/76824611/211336675-d0f4fc02-2c21-4eb6-8b04-d010d8c7f7fd.png">

**[setting]**      
* The hyperparameters are chosen on the validation set    
* Comparision with [Tang et al. (2015)](https://aclanthology.org/D15-1167.pdf)   
* tune the hyperparameters on the validation set   
 
**[Results]**   
* ë³¸ ë…¼ë¬¸ì˜ ë°©ë²•ì´  [Tang et al. (2015)](https://aclanthology.org/D15-1167.pdf)ë³´ë‹¤ ì„±ëŠ¥ì´ ë” ì¢‹ë‹¤.      
*n-grams up to 5ê°€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ë‹¤    
 
 
## 3.2 Tag prediction
 <img width="220" alt="image" src="https://user-images.githubusercontent.com/76824611/211339784-cf874ae1-d7b6-499f-893f-46b25554e835.png">

**[setting]**      
* fastText for 5 epochs    
* compare it to Tagspace for two sizes of the hidden layer 50 & 200        
 
**[Results]**   
* Both models achieve a similar performance with a small hidden layer, but **adding bigrams** gives us a **significant boost in accuracy**           
 
 
 
 

