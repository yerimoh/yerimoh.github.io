---
title: "(T5) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer ì •ë¦¬"
date:   2023-02-10
excerpt: "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer paper review"
category: #[Paper]
layout: post
tag:
#- Paper
order: 0

comments: true
---


# Abstract
<span style="background-color:#F5F5F5">**[ë…¼ë¬¸ ë°°ê²½]**</span>    
ëª¨ë¸ì´ Downstream Taskì—ì„œ fine-tuningë˜ê¸° ì „ì— data-rich taskì—ì„œ pre-trainì„ í•˜ëŠ” ê²ƒì€  ìì—°ì–´ ì²˜ë¦¬(NLP)ì˜ ê°•ë ¥í•œ ê¸°ìˆ ë¡œ ë¶€ìƒí–ˆë‹¤.     
ì¦‰ ì´ëŸ¬í•œ [transfer learning](https://yerimoh.github.io/DL12/)ì€ NLPì— í° ë°œì „ì„ ê°€ì ¸ì™”ë‹¤.    

<span style="background-color:#F5F5F5">**[ë…¼ë¬¸ì˜ ëª©ì ]**</span>    
* ëª¨ë“  í…ìŠ¤íŠ¸ ê¸°ë°˜ ì–¸ì–´ ë¬¸ì œë¥¼ text-to-text í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í•˜ì—¬ <span style="background-color:#fff5b1">NLPì— ëŒ€í•œ [transfer learning](https://yerimoh.github.io/DL12/)ë¥¼ ì „ë°˜ì ìœ¼ë¡œ íƒêµ¬</span>í•œë‹¤.     
* ìœ„ íƒêµ¬ë¥¼ í†µí•´ ì–»ì€ í†µì°°ë ¥ê³¼ ê·œëª¨ ë° ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•  <span style="background-color:#fff5b1">"Colossal Clean Crawled Corpus"ë¥¼ ê²°í•©</span>í•˜ì—¬ ë§ì€ NLP evaluationì—ì„œ SOTA ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.        
â¡ ê³µê°œí•œ [data set, pre-trained models, and code](https://github.com/google-research/text-to-text-transfer-transformer) ë§í¬ë¥¼ ì²¨ë¶€í•˜ì˜€ë‹¤.        


<details>
<summary>ğŸ“œ Downstream Task ì˜ë¯¸ ë³´ê¸°</summary>
<div markdown="1">
  

êµ¬ì²´ì ìœ¼ë¡œ í’€ê³  ì‹¶ì€ ë¬¸ì œë“¤ì„ ë§í•œë‹¤.

NLPì—ì„œëŠ” ì–¸ì–´ëª¨ë¸ì„ pre-trainë°©ì‹ì„ ì´ìš©í•´ í•™ìŠµì„ ì§„í–‰í•˜ê³ ,    
ê·¸ í›„ì— ì›í•˜ê³ ì í•˜ëŠ” taskë¥¼ fine-tuningí•˜ëŠ” ë°©ì‹ì„ í†µí•´ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸ í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ”ë° ì´ë•Œ, taskë¥¼ Downstream Taskë¼ í•œë‹¤.

ì˜ˆë¥¼ë“¤ì–´, BERTì˜ ì–¸ì–´ëª¨ë¸ì„ ì§ˆì˜ì‘ë‹µ Taskë¼ì¸ squadë¥¼ í•™ìŠµí•œë‹¤ê³  í• ë•Œ, ì´ë•Œ ì§ˆì˜ì‘ë‹µ Taskë¥¼ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ Taskë¡œ ë³¼ ìˆ˜ ìˆì„ê²ƒì´ë‹¤.  
  
  
</div>
</details>  

----
----



# Introduction

<span style="background-color:#F5F5F5">**[ìµœê·¼ ì—°êµ¬ ë™í–¥]**</span>    
ìì—°ì–´ ì²˜ë¦¬(NLP)ì‘ì„ ì„ ìœ„í•œ trainì´ ê°€ëŠ¥í•˜ì—¬ë©´ ëª¨ë¸ì´ **downstream learningì— ì í•©í•œ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬**í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.              
ê·¸ëŸ°ë° ì´ëŠ” **ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ "ì´í•´"í•  ìˆ˜ ìˆê²Œ í•™ìŠµí•œë‹¤ê³  ë³´ê¸°ì—” í˜ë“¤ë‹¤**.               
â¡ í˜„ëŒ€ ê¸°ê³„ í•™ìŠµ ê´€í–‰ì—ì„œ ì´ëŸ¬í•œ trainì´ ëª…ì‹œì ìœ¼ë¡œ ìˆ˜í–‰ë˜ëŠ” ê²½ìš°ê°€ ê±°ì˜ ì—†ì–´, ëŒ€ì‹  **Auxiliary Taskì˜ ì¼ë¶€**ë¡œ í•™ìŠµë˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.        


<details>
<summary>ğŸ“œ Auxiliary Task ì˜ë¯¸ ë³´ê¸°</summary>
<div markdown="1">

ë³¸ taskëŠ” ì•„ë‹ˆì§€ë§Œ, ë³¸ taskì—ì„œì˜ ì„±ëŠ¥ì´ ë” ì˜ ë‚˜ì˜¬ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë³´ì¡° task  

</div>
</details> 
  
ìµœê·¼ì—ëŠ” **ë°ì´í„°ê°€ í’ë¶€í•œ ì‘ì—…**ì— ëŒ€í•´ **ì „ì²´ ëª¨ë¸ì„ pre-trainí•˜ëŠ” ê²ƒ**ì´ ì ì  ë” **ì¼ë°˜í™”**ë˜ê³  ìˆë‹¤.     
ì´ìƒì ìœ¼ë¡œ, ì´ pre-trainì€ ëª¨ë¸ì´ ë²”ìš© ëŠ¥ë ¥ê³¼ ì§€ì‹ì„ ê°œë°œí•˜ê²Œ í•˜ê³ , ì´ë¥¼ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ìœ¼ë¡œ ì´ì „í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.     
â¡ ë” í° ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë” í° ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒë§Œìœ¼ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆë‹¤.    




<span style="background-color:#F5F5F5">**[í˜„ ê²½í–¥ìœ¼ë¡œ ì¸í•œ í•œê³„]**</span>    
ì´ëŸ¬í•œ ê²½í–¥ìœ¼ë¡œ ì¸í•´ NLPì— ëŒ€í•œ **transfer learning ë°©ë²•ë¡ ì„ ê°œë°œ**í•˜ëŠ” ì—°êµ¬ë“¤ì´ í™œë°œí•˜ê²Œ ì´ë£¨ì–´ì¡Œë‹¤.      
ì´ë ‡ê²Œ ì´ ë¶„ì•¼ê°€ ê¸‰ì„±ì¥í•˜ì—¬ ì—°êµ¬ê°€ í™œë°œí•´ì§€ë‹ˆ ì•„ë˜ì™€ ê°™ì€ ì‘ì—…ë“¤ì´ ì–´ë ¤ì›Œì¡Œë‹¤.       
* ì—¬ëŸ¬ algorithmsì„ ë¹„êµ    
* ìƒˆë¡œìš´ contributionsì˜ íš¨ê³¼ íŒŒì•…    
* transfer learningì„ ìœ„í•œ ê¸°ì¡´ ë°©ë²•ì˜ space ì´í•´        


âœ” ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì€ ì´ ë¶„ì•¼ì˜ ì›í™œí•œ ì´í•´ë¥¼ ìœ„í•´, **ë‹¤ì–‘í•œ ì ‘ê·¼ë²•ì„ ì²´ê³„ì ìœ¼ë¡œ ì—°êµ¬**í•˜ê³  **í•„ë“œì˜ í˜„ì¬ í•œê³„ë¥¼ ë°€ì–´ë‚¼ ìˆ˜ ìˆëŠ” transfer learningì— ëŒ€í•œ í†µí•©ëœ ì ‘ê·¼ë²•ì„ í™œìš©**í•œë‹¤. 
 


<span style="background-color:#F5F5F5">**[ë³¸ ë…¼ë¬¸ì˜ í•´ê²°ì±…]**</span>      
ë³¸ ë…¼ë¬¸ workì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” <span style="background-color:#fff5b1">ëª¨ë“  í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë¬¸ì œë¥¼ **â€œtext-to-textâ€ ë¬¸ì œë¡œ ì²˜ë¦¬**</span>í•˜ëŠ” ê²ƒì´ë‹¤.             
ì¦‰, **í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ë“¤ì´ê³  ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥ìœ¼ë¡œ ìƒì„±**í•˜ëŠ” ê²ƒì´ë‹¤.          
* ì´ëŸ¬í•œ í…ìŠ¤íŠ¸ ê°„ í”„ë ˆì„ì›Œí¬ëŠ” ìš°ë¦¬ê°€ ê³ ë ¤í•˜ëŠ” ëª¨ë“  ì‘ì—…ì— **ë™ì¼í•œ ëª¨ë¸, ëª©í‘œ, í›ˆë ¨ ì ˆì°¨ ë° decoding í”„ë¡œì„¸ìŠ¤ë¥¼ ì§ì ‘ ì ìš©**í•  ìˆ˜ ìˆê²Œ í•œë‹¤.          
* ë³¸ ë…¼ë¬¸ì€ ì§ˆë¬¸ ë‹µë³€, ë¬¸ì„œ ìš”ì•½ ë° ê°ì • ë¶„ë¥˜ë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ ì˜ì–´ ê¸°ë°˜ NLP ë¬¸ì œì— ëŒ€í•œ ì„±ëŠ¥ì„ í‰ê°€í•˜ì—¬ ì´ëŸ¬í•œ **ìœ ì—°ì„±ì„ í™œìš©**í•œë‹¤.        
* ì´ í†µí•© ì ‘ê·¼ë²•ì„ í†µí•´, ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ transfer learningì˜ target, ë ˆì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì€ ë°ì´í„° ì„¸íŠ¸ ë° ê¸°íƒ€ ìš”ì¸ì˜ íš¨ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ë™ì‹œì— ì´ì „ì— ê³ ë ¤ë˜ì—ˆë˜ ê²ƒ ì´ìƒìœ¼ë¡œ **ëª¨ë¸ê³¼ ë°ì´í„° ì„¸íŠ¸ë¥¼ í™•ì¥**í•˜ì—¬ NLPì— ëŒ€í•œ **transfer learningì˜ í•œê³„ë¥¼ íƒìƒ‰**í•  ìˆ˜ ìˆë‹¤.    




ë³¸ ë…¼ë¬¸ì€ ë³¸ ë…¼ë¬¸ì˜ ëª©í‘œê°€ ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ê·¸ ë¶„ì•¼ê°€ ì–´ë””ì— ì„œ ìˆëŠ”ì§€ì— ëŒ€í•œ í¬ê´„ì ì¸ ê´€ì ì„ ì œê³µí•˜ëŠ” ê²ƒ**ì„ì„ ê°•ì¡°í•œë‹¤.      
ì¦‰, ìš°ë¦¬ì˜ ì‘ì—…ì€ ë³¸ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì€ taskë¡œ êµ¬ì„±ëœë‹¤.         
â¡ ì£¼ë¡œ ê¸°ì¡´ ê¸°ìˆ ì˜ ì¡°ì‚¬, íƒêµ¬ ë° ê²½í—˜ì  ë¹„êµ       


ë˜í•œ ë³¸ ë…¼ë¬¸ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ **í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì˜ í•œê³„ë¥¼ íƒêµ¬**í•œë‹¤.        
ë³¸ ë…¼ë¬¸ì´ ê³ ë ¤í•˜ëŠ” ë§ì€ taskì—ì„œ SOTA ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ì²´ê³„ì ì¸ ì—°êµ¬(train ëª¨ë¸ì„ ìµœëŒ€ 110ì–µ ê°œ parametersê¹Œì§€ í™•ì¥)ìˆ˜í–‰       
* ì´ ê·œëª¨ì˜ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì›¹ì—ì„œ ê¸ì–´ë‚¸ ìˆ˜ë°± ê¸°ê°€ë°”ì´íŠ¸ì˜ clean ì˜ì–´ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±ëœ ë°ì´í„° ì„¸íŠ¸ì¸ "Colossal Clean Crawled Corpus"**(C4)** ë¥¼ ì†Œê°œí•œë‹¤.        
* **transfer learningì˜ í•µì‹¬ ê¸°ëŠ¥**ì€, **ë°ì´í„°ê°€ ë¶€ì¡±í•œ í™˜ê²½ì—ì„œ  pre-trained modelsì„ í™œìš©í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±**ì´ë¼ëŠ” ê²ƒì„ ì¸ì‹í•˜ì—¬,      
[ì½”ë“œ, ë°ì´í„° ì„¸íŠ¸ ë° ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸](https://github.com/google-research/text-to-text-transfer-transformer
)ì„ ë¦´ë¦¬ìŠ¤í–ˆë‹¤.    




<span style="background-color:#F5F5F5">**[ë…¼ë¬¸ êµ¬ì„±]**</span>            
* base modelê³¼ ê·¸ êµ¬í˜„    
* ëª¨ë“  text processing ë¬¸ì œë¥¼ text-to-text ì‘ì—…ìœ¼ë¡œ ê³µì‹í™”í•˜ëŠ” ì ˆì°¨ ë° ê³ ë ¤í•˜ëŠ” ì‘ì—… ëª¨ìŒì— ëŒ€í•œ ë…¼ì˜    
* ì„¹ì…˜ 3ì—ì„œ, NLPì— ëŒ€í•œ transfer learning ë¶„ì•¼ë¥¼ íƒêµ¬í•˜ëŠ” ëŒ€ê·œëª¨ ì‹¤í—˜ ì„¸íŠ¸ë¥¼ ì œì‹œ          
* ì„¹ì…˜(ì„¹ì…˜ 3.7)ì˜ ëì—ì„œ, ìš°ë¦¬ëŠ” ì²´ê³„ì ì¸ ì—°êµ¬ì˜ í†µì°°ë ¥ì„ ê²°í•©í•˜ì—¬ ê´‘ë²”ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ì–»ìŒ    
* ì„¹ì…˜ 4ì—ì„œ, ê²°ê³¼ì— ëŒ€í•œ ìš”ì•½ì„ ì œê³µ í•œ ë’¤, ë¯¸ë˜ì— ëŒ€í•œ ì „ë§ìœ¼ë¡œ ë§ˆë¬´ë¦¬             




---
---


# 2. Setup    



ë³¸ ë…¼ë¬¸ì€ large-scale ê²½í—˜ì  ì—°êµ¬ì˜ ê²°ê³¼ë¥¼ ì œì‹œí•˜ê¸° ì „ì— ì•„ë˜ì™€ ê°™ì€ ê²ƒë“¤ì„ ë¨¼ì € ì œì‹œí•œë‹¤,   
* [Transformer ëª¨ë¸ ì•„í‚¤í…ì²˜](https://yerimoh.github.io/Lan/)ì™€ í‰ê°€í•˜ëŠ” downstream tasksì„ í¬í•¨í•˜ì—¬ ê²°ê³¼ë¥¼ ì´í•´í•˜ëŠ” ë° í•„ìš”í•œ **ë°°ê²½ ì£¼ì œë¥¼ ê²€í† **í•œë‹¤.        
* **ëª¨ë“  ë¬¸ì œë¥¼ text-to-text taskìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì ‘ê·¼ ë°©ì‹**ì„ ì†Œê°œ    
* **"Colossal Clean Crawled Corpus"(C4) ì„¤ëª…:** ë ˆì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ ì†ŒìŠ¤ë¡œ ìƒì„±í•œ ê³µí†µ í¬ë¡¤ ê¸°ë°˜ ë°ì´í„° ì„¸íŠ¸ì„     




ìš°ë¦¬ëŠ” ìš°ë¦¬ì˜ ëª¨ë¸ê³¼ í”„ë ˆì„ì›Œí¬ë¥¼  <span style="background-color:#fff5b1">â€œText-to-Text Transfer Transformerâ€ (T5)</span> ë¼ê³  ë¶€ë¥¸ë‹¤.      





---


## 2.1 Model

### base architecture: â€œTransformerâ€
NLPì— ëŒ€í•œ ì „ì´ í•™ìŠµì— ëŒ€í•œ ì´ˆê¸° ê²°ê³¼ëŠ” ë°˜ë³µ ì‹ ê²½ë§ì„ í™œìš©í–ˆì§€ë§Œ,  
ìµœê·¼ì—ëŠ” "Transformer" ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì¼ë°˜í™”ë˜ì—ˆë‹¤.     


TransformerëŠ” transfer learningì— íš¨ê³¼ì ì´ë¯€ë¡œ, ì´í›„ ë‹¤ì–‘í•œ NLP ì„¤ì •ì— ì‚¬ìš©ë˜ì—ˆë‹¤.          
ë³¸ ë…¼ë¬¸ì—ì„œë„ **ëª¨ë“  ëª¨ë¸ì˜ baseë¥¼ Transformer ì•„í‚¤í…ì²˜**ë¡œ í•˜ì˜€ë‹¤.         

ì•„ë˜ì— ì–¸ê¸‰ëœ ì„¸ë¶€ì‚¬í•­ê³¼ ì„¹ì…˜ 3.2ì—ì„œ íƒêµ¬í•œ ë³€í˜•ì„ ì œì™¸í•˜ê³ ,     
ë³¸ ë…¼ë¬¸ì€ Transformer ì•„í‚¤í…ì²˜ì—ì„œ í¬ê²Œ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ”ë‹¤.      


<details>
<summary>ğŸ“œ Transformerë¥¼ ìì„¸íˆ ì•Œê³  ì‹¶ë‹¤ë©´? (ì°¸ê³ ìë£Œ) </summary>
<div markdown="1">

ì´ ë…¼ë¬¸(ì•„í‚¤í…ì²˜)ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œê³ ì‹¶ë‹¤ë©´ ì•„ë˜ ìë£Œë“¤ì„ ì°¸ê³ í•˜ì,    
* [ì›ë³¸ ë…¼ë¬¸](https://arxiv.org/abs/1706.03762)    
* í›„ì† íŠœí† ë¦¬ì–¼ 3,4(ë’¤ì— ë‚˜ì˜µë‹ˆë‹¤.)    
* [ë³¸ í¬ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•œ í•„ìê°€ ì •ë¦¬í•œ í¬ìŠ¤íŠ¸](https://yerimoh.github.io/Lan/)         

</div>
</details> 
  85.5


ê·¸ë¦¬ê³  ë³¸ ë…¼ë¬¸ì—ì„œ Transformerì—ëŒ€í•´ ê°„ë‹¨ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤¬ëŠ”ë° ì›í•œë‹¤ë©´ ì•„ë˜ ìì„¸í•œ ì„¤ëª… ë³´ê¸°ë¥¼ ëˆŒëŸ¬ í•œ ë²ˆ ì½ì–´ë³´ê¸¸ ë°”ë€ë‹¤.(ê·¸ë ‡ì§€ë§Œ ì› ë…¼ë¬¸ì„ ì½ì–´ë´ì•¼ ì•„ë˜ ë‚´ìš©ë“¤ë„ ì´í•´ê°€ ê°ˆ ê²ƒì´ë‹¤.)   

<details>
<summary>ğŸ“œ Transformerë¥¼ ìì„¸íˆ ì•Œê³  ì‹¶ë‹¤ë©´?(ë³¸ ë…¼ë¬¸ì˜ ì„¤ëª…) </summary>
<div markdown="1">




 
**Transformerì˜ ì¤‘ìš”í•œ ìš”ì†ŒëŠ”,** [self-attention](https://yerimoh.github.io/Lan/#sub-layer1-self-attention)ì´ë‹¤.         
self-attentionì€ ê° ìš”ì†Œë¥¼ ë‚˜ë¨¸ì§€ sequenceì˜ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” attentionì˜ ë³€í˜•ì´ë‹¤.    

**Transformerì˜ êµ¬ì¡°ëŠ”,** [encoder-decoder ì•„í‚¤í…ì²˜](https://yerimoh.github.io/Lan/#transformer-%EB%AA%A8%EB%8D%B8-%EA%B0%9C%EC%9A%94)ë¡œ êµ¬ì„±ë˜ì—ˆìœ¼ë©° sequence-to-sequence ì‘ì—…ì„ ìœ„í•´ ê³ ì•ˆë˜ì—ˆë‹¤.        

ì „ë°˜ì ìœ¼ë¡œ, ë³¸ ë…¼ë¬¸ ëª¨ë¸ì˜ encoder-decoder Transformerì˜ êµ¬í˜„ì€ ì›ë˜ Transformerì˜ í˜•íƒœë¥¼ ë°€ì ‘í•˜ê²Œ ë”°ë¥¸ë‹¤.               

**[Transformerì˜ ë™ì‘ ê³¼ì •]**       
* **1)** í† í°ì˜ input sequenceë¥¼ embeddings sequenceë¥¼ì— ë§¤í•‘í•œ ë‹¤ìŒ encoderë¡œ ì „ë‹¬í•œë‹¤.      
* **2)** encoderëŠ”  â€œblocksâ€ì˜ ìŠ¤íƒìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ê° ìŠ¤íƒë§ˆë‹¤ self-attention layer ê³„ì¸µê³¼ small feed-forward networkë¥¼ ê°–ê³ ìˆë‹¤.     
* **3)** ê° ìŠ¤íƒ ì•ˆì˜ 2ê°€ì§€ ìš”ì†Œë“¤ì˜ ì…ë ¥ì—ëŠ” Layer normalizationê°€ ì ìš©ëœë‹¤.     
* **4)** ì´í›„, activationsì´ ì¬ì¡°ì •ë˜ê³  ì¶”ê°€ biasì´ ì ìš©ë˜ì§€ ì•ŠëŠ” ë‹¨ìˆœí™”ëœ ë²„ì „ì˜ Layer normalizationë¥¼ ì‚¬ìš©í•œë‹¤.      
* **5)** layer normalization í›„, residual skip connectionì€ ê° ìŠ¤íƒ ì•ˆì˜ 2ê°€ì§€ ìš”ì†Œì˜ ì…ë ¥ì„ ì¶œë ¥ì— ì¶”ê°€í•œë‹¤.      
* **6)** ë“œë¡­ì•„ì›ƒì€ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë‚´ì—ì„œ ìŠ¤í‚µ ì—°ê²°, ì£¼ì˜ ê°€ì¤‘ì¹˜ ë° ì „ì²´ ìŠ¤íƒì˜ ì…ë ¥ ë° ì¶œë ¥ì— ì ìš©ëœë‹¤.   
* **7)** decoderëŠ” encoderì˜ ì¶œë ¥ì— ì°¸ì—¬í•˜ëŠ” ê° self-attention layer ë‹¤ìŒì— standard attention ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•œë‹¤ëŠ” ì ì„ ì œì™¸í•˜ê³ ëŠ” ì¸ì½”ë”ì™€ êµ¬ì¡°ê°€ ìœ ì‚¬í•˜ë‹¤.       
decoderì˜ self-attention ë©”ì»¤ë‹ˆì¦˜ì€ ëª¨ë¸ì´ ê³¼ê±° ì¶œë ¥ì—ë§Œ ì£¼ì˜ë¥¼ ê¸°ìš¸ì¼ ìˆ˜ ìˆë„ë¡ í•œë‹¤.     
* **8)** ìµœì¢… decoder ë¸”ë¡ì˜ ì¶œë ¥ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì¶œë ¥ì„ ê°€ì§„  dense ë ˆì´ì–´ë¡œ ë“¤ì–´ê°€ë©°, ê·¸ ê°€ì¤‘ì¹˜ëŠ” ì…ë ¥ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ì™€ ê³µìœ ëœë‹¤.      
* âœ¨ ì—¬ê¸°ì„œ, íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ëª¨ë“  attention ë©”ì»¤ë‹ˆì¦˜ì€ ì¶”ê°€ë¡œ ì²˜ë¦¬ë˜ê¸° ì „ì— ì¶œë ¥ì´ ì—°ê²°ë˜ëŠ” ë…ë¦½ì ì¸ â€œheadsâ€ë¡œ ë‚˜ë‰˜ì–´ìˆë‹¤.          
![image](https://user-images.githubusercontent.com/76824611/132572962-94a60e8b-2182-466a-8d1d-47a86ee83a14.gif)
</div>
</details> 
  


### relative position embeddings
Transformerì˜ self-attentionëŠ” ë³‘ë ¬ì²˜ë¦¬ë¥¼í•˜ì—¬ ìˆœì„œ ì •ë³´ë¥¼ ê°–ì§€ ëª»í•˜ë¯€ë¡œ, ì„ë² ë”©ì— ìˆœì„œì •ë³´ë¥¼ ë„£ì–´ì¤€ë‹¤.    
ì´ ë…¼ë¬¸ì—ì„œëŠ” ê¸°ì¡´ Transformerì™€ ë‹¤ë¥¸ ìœ„ì¹˜ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì˜€ë‹¤.     
* **ê¸°ì¡´ ëª¨ë¸**: sinusoidal position signal or learned position embeddings (ë‹¨ì–´ì˜ ì ˆëŒ€ì  ìœ„ì¹˜ ì •ë³´ í‘œí˜„)           
* **T5**: [relative position embeddings](https://yerimoh.github.io/LAN18/) (ë‹¨ì–´ì˜ ìƒëŒ€ì  ìœ„ì¹˜ í‘œí˜„)     


      



<details>
<summary>ğŸ“œ relative position embeddingsë¥¼ ìì„¸íˆ ì•Œê³  ì‹¶ë‹¤ë©´?(ë³¸ ë…¼ë¬¸ì˜ ì„¤ëª…) </summary>
<div markdown="1">

ê° ìœ„ì¹˜ì— ëŒ€í•´ ê³ ì • ì„ë² ë”©ì„ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , relative position embeddingsì€ self-attentionì—ì„œ ë¹„êµë˜ëŠ” "key"ì™€ "query" ì‚¬ì´ì˜ ì˜¤í”„ì…‹ì— ë”°ë¼ ë‹¤ë¥¸ í•™ìŠµëœ ì„ë² ë”©ì„ ìƒì„±í•œë‹¤.    

ë˜í•œ íš¨ìœ¨ì„±ì„ ìœ„í•´ **ëª¨ë¸ì˜ ëª¨ë“  ë ˆì´ì–´**ì— ê±¸ì³ **position embeddings parametersë¥¼ ê³µìœ **í•˜ì§€ë§Œ,     
**ì£¼ì–´ì§„ layer ë‚´**ì—ì„œ **ê° attention head**ëŠ” **ì„œë¡œ ë‹¤ë¥¸ í•™ìŠµëœ position embeddingì„ ì‚¬ìš©**í•œë‹¤.      

ì¼ë°˜ì ìœ¼ë¡œ, ê°ê° ê°€ëŠ¥í•œ "key"ì™€ "query" ì˜¤í”„ì…‹ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” **ê³ ì •ëœ ìˆ˜ì˜ embeddings**ì´ í•™ìŠµëœë‹¤.      

ì´ ì—°êµ¬ì—ì„œ, ìš°ë¦¬ëŠ” ë¡œê·¸ì ìœ¼ë¡œ **ìµœëŒ€ 128ì˜ ì˜¤í”„ì…‹ê¹Œì§€ í¬ê¸°ê°€ ì¦ê°€**í•˜ëŠ” ë²”ìœ„ë¥¼ ê°€ì§„ **ëª¨ë“  ëª¨ë¸**ì—    
**32ê°œì˜ embeddingì„ ì‚¬ìš©**í•˜ì—¬ ëª¨ë“  relative positionë¥¼ ë™ì¼í•œ ì„ë² ë”©ì— í• ë‹¹í•œë‹¤.      

íŠ¹ì • ê³„ì¸µì€ 128ê°œ í† í°ì„ ì´ˆê³¼í•˜ëŠ” relative positionì— ë¯¼ê°í•˜ì§€ ì•Šì§€ë§Œ,     
subsequent ê³„ì¸µì€ ì´ì „ ê³„ì¸µì˜ ë¡œì»¬ ì •ë³´ë¥¼ ê²°í•©í•˜ì—¬ ë” í° ì˜¤í”„ì…‹ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•  ìˆ˜ ìˆë‹¤.

</div>
</details> 
  
**[summary: T5ì™€ ê¸°ì¡´ Transformerì˜ ì°¨ì´ì ]**       
ì•„ë˜ë¥¼ ì œì™¸í•˜ê³  ê¸°ì¡´ Transformerì™€ ë™ì¼       
* T5ëŠ” Layer Norm biasë¥¼ ì œê±°í•¨    
* Layer normalizationë¥¼ residual path ì™¸ë¶€ì— ë°°ì¹˜     
* ë‹¤ë¥¸ position embedding ë°©ì‹ ì‚¬ìš©(relative position embeddings)    

ì´ëŸ¬í•œ ì•„í‚¤í…ì²˜ ë³€í™”ëŠ” transfer learningì— ëŒ€í•œ ê²½í—˜ì  ì¡°ì‚¬ì—ì„œ ê³ ë ¤í•˜ëŠ” ì‹¤í—˜ ìš”ì†Œì™€ ì§êµí•˜ê¸° ë•Œë¬¸ì—,  
ìš°ë¦¬ëŠ” í–¥í›„ ì‘ì—…ì„ ìœ„í•´ ì˜í–¥ì˜ ì ˆì œë¥¼ ë‚¨ê²¨ë‘ ë‘ .  
  
### ì‹¤í—˜  
* T5ì˜ í™•ì¥ì„±(scalability)ì‹¤í—˜    
â¡ ì¦‰ ë” ë§ì€ parametersë‚˜ layersì„ ê°€ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì‹¤í—˜í•œë‹¤.      
* ê²°ê³¼ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ëª¨ë¸ê³¼ ë°ì´í„° ë³‘ë ¬í™”ë¥¼ ê²°í•©í•˜ì—¬ â€œslicesâ€ of Cloud TPU Pods"ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚´.       



----

##  2.2 The Colossal Clean Crawled Corpus
ë°ì´í„°ëŠ”  **large unlabeled** data sets for **unsupervised learning**ë¥¼ ì‚¬ìš©í•œë‹¤.    

í…ìŠ¤íŠ¸ ë°ì´í„° ì†ŒìŠ¤ëŠ” **Common Crawl**ì„ ì‚¬ìš©í•œë‹¤


<details>
<summary>ğŸ“œ Common Crawlì„ ìì„¸íˆ ì•Œê³  ì‹¶ë‹¤ë©´? </summary>
<div markdown="1">
  
Common Crawlì´ë€    
* ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì›¹ ì•„ì¹´ì´ë¸Œì„     
* ìŠ¤í¬ë©ëœ HTML íŒŒì¼ì—ì„œ ë§ˆí¬ì—… ë° ê¸°íƒ€ ë¹„í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ì œê±°í•˜ì—¬ "ì›¹ ì¶”ì¶œ í…ìŠ¤íŠ¸"ë¥¼ ì œê³µ      
* ì´ í”„ë¡œì„¸ìŠ¤ëŠ” ë§¤ë‹¬ ì•½ 20TBì˜ ìŠ¤í¬ë©ëœ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±.     


preprocessing     
* Common Crawlì˜ ë¬¸ì œ     
   * ë¶ˆí–‰í•˜ê²Œë„, Common Crawlì˜ ê²°ê³¼ í…ìŠ¤íŠ¸ì˜ ëŒ€ë¶€ë¶„ì€ ìì—°ì–´ê°€ ì•„ë‹ˆë‹¤.     
   * ì˜¤ë¥˜ ë©”ì‹œì§€ ë˜ëŠ” ì¤‘ë³µ í…ìŠ¤íŠ¸ì™€ ê°™ì€ íš¡ì„¤ìˆ˜ì„¤í•˜ê±°ë‚˜ boiler-plate í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±ë¨    
* í•´ê²°: ë‹¤ìŒ íœ´ë¦¬ìŠ¤í‹±ì„ ì‚¬ìš©     
   * ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ë˜ëŠ” ë ë”°ì˜´í‘œë¡œ ëë‚˜ëŠ” í–‰ë§Œ ì¶”ì¶œ     
   * 5ê°œ ë¯¸ë§Œì˜ ë¬¸ì¥ì´ ìˆëŠ” í˜ì´ì§€ëŠ” íê¸°í•˜ê³  ìµœì†Œ 3ê°œì˜ ë‹¨ì–´ê°€ í¬í•¨ëœ í–‰ë§Œ ì¶”ì¶œ      
   * "ë”í‹°, ì¥ë‚œ, ì™¸ì„¤ ë˜ëŠ” ê¸°íƒ€ ë‚˜ìœ ë‹¨ì–´ ëª©ë¡"ì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ê°€ í¬í•¨ëœ í˜ì´ì§€ë¥¼ ì œê±°          
   * ëŒ€ë¶€ë¶„ì˜ ìŠ¤í¬ë© í˜ì´ì§€ì—ëŠ” Javascriptë¥¼ í™œì„±í™”í•´ì•¼ í•œë‹¤ëŠ” ê²½ê³ ê°€ í¬í•¨ë˜ì–´ ìˆì–´ Javascriptë¼ëŠ” ë‹¨ì–´ê°€ ìˆëŠ” ì¤„ì€ ëª¨ë‘ ì œê±°          
   * ì¼ë¶€ í˜ì´ì§€ì—ëŠ” í”Œë ˆì´ìŠ¤í™€ë” "lorem ipsum" í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, "lorem ipsum"ì´ë¼ëŠ” ë¬¸êµ¬ê°€ ë‚˜íƒ€ë‚˜ëŠ” í˜ì´ì§€ëŠ” ëª¨ë‘ ì œê±°      
   *  "{"ê°€ í¬í•¨ëœ ëª¨ë“  í˜ì´ì§€ë¥¼ ì œê±°     
   *  ë°ì´í„° ì„¸íŠ¸ì˜ ì¤‘ë³µì„ ì œê±°í•˜ê¸° ìœ„í•´ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë‘ ë²ˆ ì´ìƒ ë°œìƒí•˜ëŠ” ì„¸ ë¬¸ì¥ ë²”ìœ„ ì¤‘ í•˜ë‚˜ë¥¼ ì œì™¸í•˜ê³  ëª¨ë‘ ì‚­ì œ     


</div>
</details> 

-----

## 2.3 Downstream Tasks
* Sentence acceptability judgment (CoLA (Warstadt et al., 2018))     
* Sentiment analysis (SST-2 (Socher et al., 2013))    
* Paraphrasing/sentence similarity (MRPC (Dolan and Brockett, 2005), STS-B (Ceret al., 2017), QQP (Iyer et al., 2017))    
* Natural language inference (MNLI (Williams et al., 2017), QNLI (Rajpurkar et al.,2016), RTE (Dagan et al., 2005), CB (De Marneff et al., 2019))      
* Coreference resolution (WNLI and WSC (Levesque et al., 2012))   
* Sentence completion (COPA (Roemmele et al., 2011))   
* Word sense disambiguation (WIC (Pilehvar and Camacho-Collados, 2018))   
* Question answering (MultiRC (Khashabi et al., 2018), ReCoRD (Zhang et al., 2018), BoolQ (Clark et al., 2019))      


------

## 2.4 Input and Output Format

In order to train a single model on the diverse set of tasks described above, we cast all of
the tasks we consider into a â€œtext-to-textâ€ formatâ€”that is, a task where the model is fed
some text for context or conditioning and is then asked to produce some output text. This
framework provides a consistent training objective both for pre-training and fine-tuning.
Specifically, the model is trained with a maximum likelihood objective (using â€œteacher forcingâ€
(Williams and Zipser, 1989)) regardless of the task. To specify which task the model should
perform, we add a task-specific (text) prefix to the original input sequence before feeding it
to the model.



As an example, to ask the model to translate the sentence â€œThat is good.â€ from English
to German, the model would be fed the sequence â€œtranslate English to German: That is
good.â€ and would be trained to output â€œDas ist gut.â€ For text classification tasks, the
model simply predicts a single word corresponding to the target label. For example, on the
MNLI benchmark (Williams et al., 2017) the goal is to predict whether a premise implies
(â€œentailmentâ€), contradicts (â€œcontradictionâ€), or neither (â€œneutralâ€) a hypothesis. With
our preprocessing, the input sequence becomes â€œmnli premise: I hate pigeons. hypothesis:
My feelings towards pigeons are filled with animosity.â€ with the corresponding target word
â€œentailmentâ€. Note that an issue arises if our model outputs text on a text classification
task that does not correspond to any of the possible labels (for example if the model
outputs â€œhamburgerâ€ when the only possible labels for a task were â€œentailmentâ€, â€œneutralâ€,
or â€œcontradictionâ€). In this case, we always count the modelâ€™s output as wrong, though we
never observed this behavior in any of our trained models. Note that the choice of text prefix
used for a given task is essentially a hyperparameter; we found that changing the exact
wording of the prefix had limited impact and so did not perform extensive experiments into
different prefix choices. A diagram of our text-to-text framework with a few input/output
examples is shown in Figure 1. We provide full examples of preprocessed inputs for every
task we studied in Appendix D



Our text-to-text framework follows previous work that casts multiple NLP tasks into
a common format: McCann et al. (2018) propose the â€œNatural Language Decathlonâ€, a
benchmark that uses a consistent question-answering format for a suite of ten NLP tasks.
The Natural Language Decathlon also stipulates that all models must be multi-task, i.e.
are able to simultaneously tackle all of the tasks at once. We instead allow for separately
fine-tuning the model on each individual task and use short task prefixes instead of an explicit
question-answer format. Radford et al. (2019) evaluate the zero-shot learning capabilities of
language models by feeding some input to the model as a prefix and then autoregressively
sampling an output. For example, automatic summarization is done by feeding in a document
followed by the text â€œTL;DR:â€ (short for â€œtoo long, didnâ€™t readâ€, a common abbreviation)
and then the summary is predicted via autoregressive decoding. We mainly consider models
that explicitly process an input with an encoder before generating an output with a separate
decoder and we focus on transfer learning rather than zero-shot learning. Finally, Keskar
et al. (2019b) unify many NLP tasks as â€œspan extractionâ€, where text corresponding to
possible output choices are appended to the input and the model is trained to extract the
input span corresponding to the correct choice. In contrast, our framework also allows for
generative tasks like machine translation and abstractive summarization where it is not
possible to enumerate all possible output choices.


We were able to straightforwardly cast all of the tasks we considered into a text-to-text
format with the exception of STS-B, which is a regression task where the goal is to predict
a similarity score between 1 and 5. We found that most of these scores were annotated
in increments of 0.2, so we simply rounded any score to the nearest increment of 0.2 and
converted the result to a literal string representation of the number (e.g. the floating-point
value 2.57 would be mapped to the string â€œ2.6â€). At test time, if the model outputs a
string corresponding to a number between 1 and 5, we convert it to a floating-point value;
otherwise, we treat the modelâ€™s prediction as incorrect. This effectively recasts the STS-B
regression problem as a 21-class classification problem.


Separately, we also convert the Winograd tasks (WNLI from GLUE, WSC from SuperGLUE, and the DPR data set we add to SuperGLUE) into a simpler format that is more
amenable to the text-to-text framework. Examples from the Winograd tasks consist of a
text passage containing an ambiguous pronoun that could refer to more than one of the noun
phrases in the passage. For example, the passage might be â€œThe city councilmen refused
the demonstrators a permit because they feared violence.â€, which contains the ambiguous
pronoun â€œtheyâ€ that could refer to â€œcity councilmenâ€ or â€œdemonstratorsâ€. We cast the WNLI,
WSC, and DPR tasks as text-to-text problems by highlighting the ambiguous pronoun in
the text passage and asking the model to predict the noun that it refers to. The example
mentioned above would be transformed to the input â€œThe city councilmen refused the
demonstrators a permit because *they* feared violence.â€ and the model would be trained to
predict the target text â€œThe city councilmen


For WSC, examples contain the passage, the ambiguous pronoun, a candidate noun,
and a True/False label reflecting whether the candidate matches the pronoun (ignoring any
articles). We only train on examples with a â€œTrueâ€ label since we do not know the correct
noun targets for examples with a â€œFalseâ€ label. For evaluation, we assign a â€œTrueâ€ label if
the words in the modelâ€™s output are a subset of the words in the candidate noun phrase
(or vice versa) and assign a â€œFalseâ€ label otherwise. This removes roughly half of the WSC
training set, but the DPR data set adds about 1,000 pronoun resolution examples. Examples
from DPR are annotated with the correct referent noun, making it easy to use this data set
in the format listed above.


For WSC, examples contain the passage, the ambiguous pronoun, a candidate noun,
and a True/False label reflecting whether the candidate matches the pronoun (ignoring any
articles). We only train on examples with a â€œTrueâ€ label since we do not know the correct
noun targets for examples with a â€œFalseâ€ label. For evaluation, we assign a â€œTrueâ€ label if
the words in the modelâ€™s output are a subset of the words in the candidate noun phrase
(or vice versa) and assign a â€œFalseâ€ label otherwise. This removes roughly half of the WSC
training set, but the DPR data set adds about 1,000 pronoun resolution examples. Examples
from DPR are annotated with the correct referent noun, making it easy to use this data set
in the format listed above. practice (Devlin et al., 2018) due to the fact that it is â€œadversarialâ€ with respect to the
training set, i.e. validation examples are all slightly-perturbed versions of training examples
with the opposite label. As such, we do not include WNLI in the average GLUE score
whenever we report on the validation set (all sections except Section 3.7 where results
are presented on the test sets). Converting examples from WNLI to the â€œreferent noun
predictionâ€ variant described above is a little more involved; we describe this process in
Appendix B.






















