---
title: "[012] Deep learning 1:Transfer Learning"
date:   2020-02-28
excerpt: "ì „ì´ í•™ìŠµ(Transfer Learning) "
category: [Deep Learning]
layout: post
tag:
- Deep Learning
order: 0

comments: true
---


# ì „ì´ í•™ìŠµ(Transfer Learning) 
ì§€ê¸ˆê¹Œì§€ ëŒ€ê·œëª¨ ë°ì´í„°ì„¸íŠ¸ì— ëŒ€í•´ [ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸](https://yerimoh.github.io/DL11/)ì„ ë‹¤ìš´       
í•˜ì§€ë§Œ,       
âœ” í•„ìš”í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ì„ **ì°¾ì„ ìˆ˜ ì—†ì„ë•Œ**     
âœ” ëª¨ë¸ì„ ì²˜ìŒë¶€í„° íŠ¸ë ˆì´ë‹í•˜ê¸° ìœ„í•œ ì¶©ë¶„íˆ **í¬ê³  ë‹¤ì–‘í•œ ë°ì´í„°ì„¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš°**       

**ì „ì´í•™ìŠµ**ì„ ì´ìš©í•˜ë©´ ëœë‹¤!!!     
â¡ **ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸**ì„ ì›ë˜ì˜ íŠ¸ë ˆì´ë‹ ì‘ì—…ê³¼ ì–´ëŠ ì •ë„ ì¤‘ì²©ë˜ëŠ” ì‘ì—…ì— ëŒ€í•´ **ë‹¤ì‹œ íŠ¸ë ˆì´ë‹**ê°€ëŠ¥    
â¡ **ì†Œê·œëª¨ ë°ì´í„°ì„¸íŠ¸**ì— ëŒ€í•´ ì •í™•í•˜ê³  ê°•ë ¥í•œ ëª¨ë¸ì„ íŠ¸ë ˆì´ë‹í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„± ë†’ìŒ   



## êµ¬í˜„í•˜ê¸° ì „ ì½ì–´ ë³¼ ì§€ì‹
* ğŸ“Œ**í•„ìˆ˜**ğŸ“Œ[Pre-Trained Models](https://yerimoh.github.io/DL11/): ì´ ëª¨ë¸ì„ ì‚¬ìš©í•  ê²ƒì´ë‹¤    

## ëª©í‘œ
* ì „ì´ í•™ìŠµì„ ìœ„í•œ ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ ì¤€ë¹„    
* ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ë¡œ ìì²´ì ì¸ ì†Œê·œëª¨ ë°ì´í„°ì„¸íŠ¸ì— ëŒ€í•´ ì „ì´ í•™ìŠµ ìˆ˜í–‰    
* í›¨ì”¬ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ„í•´ ëª¨ë¸ì„ ì¶”ê°€ë¡œ íŒŒì¸íŠœë‹    


-------

# ë§ì¶¤í˜• ë¶„ë¥˜ê¸°
ì „ì— êµ¬í˜„í•œ ê°œë§Œ ì¶œì…ì´ ê°€ëŠ¥í•œ [ê°œêµ¬ë©](https://yerimoh.github.io/DL11/)ì—ì„œ íŠ¹ì •í•œ ê°œë§Œ ì¶œì…ì´ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ì–´ ë³´ê² ë‹¤.       
*  Boë¼ëŠ” ê°œë¥¼ ìœ„í•œ ìë™ ê°œêµ¬ë©ì„ ë§Œë“¤ì–´ ë³´ê² ë‹¤!! -> ë‹¤ë¥¸ ê°œë¥¼ ë¶„ë¥˜í•˜ê³ ì‹¶ìœ¼ë©´ ê·¸ ê°œì˜ ì‚¬ì§„ì„ ì™•ì°½ ê°€ì ¸ì˜¤ì!!  
*  **ë¬¸ì œ**: Boë¼ëŠ” ê°œì˜ ì‚¬ì§„ì´ 30ê°œ ë°–ì— ì—†ë‹¤(í¬ê³  ë‹¤ì–‘í•œ ë°ì´í„° ì„¸íŠ¸ê°€ ì—†ë‹¤ëŠ” ê²ƒì´ë‹¤)   
      
![image](https://user-images.githubusercontent.com/76824611/129334103-2874e112-f348-421d-bae4-c6b9b78a9f88.png)


## ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
**```VGG16```ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´**: 1,000ê°œì˜ ë¶„ë¥˜ ë¼ë²¨ ì¤‘ í•˜ë‚˜ì˜ ë™ë¬¼ë¡œ ë¶„íœ´í•˜ëŠ” ë°€ì§‘ ë ˆì´ì–´      
**í•„ìš”í•œ ë§ˆì§€ë§‰ ë ˆì´ì–´**: Boì¸ì§€ ì•„ë‹Œì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë ˆì´ì–´       
â¡ ì¦‰, ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ë¥¼ ì œê±°í•´ì•¼í•¨    

```include_top=False```: ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ ì œê±°   
* ì œê±° í›„ì—” ìš°ë¦¬ê°€ ì›í•˜ëŠ” ìƒˆ ë ˆì´ì–´ ì¶”ê°€ ê°€ëŠ¥    

```python
from tensorflow import keras

base_model = keras.applications.VGG16(
    weights='imagenet',  # Load weights pre-trained on ImageNet.
    input_shape=(224, 224, 3),
    include_top=False)
```

ê·¸ëŸ¼ ëª¨ë¸ì„ í™•ì¸í•´ë³´ì

```python
base_model.summary()
```

<details>
<summary>ğŸ‘€ ê²°ê³¼ ë³´ê¸° </summary>
<div markdown="1">


```python
Model: "vgg16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
```

</div>
</details>

----


# ê¸°ë³¸ ëª¨ë¸ ë™ê²°
ìƒˆ ë ˆì´ì–´ë¥¼ ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ì— ì¶”ê°€í•˜ê¸° ì „ ìˆ˜í–‰í•´ì•¼í•  ì¤‘ìš”í•œ ë‹¨ê³„        
ëª¨ë¸ì˜ ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ë ˆì´ì–´ë¥¼ ë™ê²°í•´ì•¼ í•¨    
* íŠ¸ë ˆì´ë‹í•  ë•Œ ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ì—ì„œ **ê¸°ë³¸ ë ˆì´ì–´ëŠ” ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠëŠ” ê²ƒ**      
* ìƒˆë¡œìš´ ë¶„ë¥˜ë¥¼ ìœ„í•´ ìš°ë¦¬ê°€ **ëì— ì¶”ê°€í•˜ëŠ” ìƒˆ ë ˆì´ì–´ë§Œ ì—…ë°ì´íŠ¸**

**ì´ˆê¸°ì— ë™ê²°í•˜ëŠ” ì´ìœ **: ì¤‘ìš”í•œ ì •ë³´ê°€ ì†ì‹¤ë  ê°€ëŠ¥ì„±ì„ ë°°ì œí•˜ê¸° ìœ„í•´      
* ë‚˜ì¤‘ì— íŒŒì¸íŠœë‹ì´ë¼ëŠ” ê³¼ì •ì—ì„œ ì´ëŸ¬í•œ ë ˆì´ì–´ë¥¼ ë™ê²° í•´ì œí•˜ê³  íŠ¸ë ˆì´ë‹í•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì¡´ì¬    
*  ê·¸ëŸ¬ë¯€ë¡œ í•„ìš”ì‹œ íŒŒì¸íŠœë‹ì—ì„œ ê³ ì¹˜ë©´ ëŒ  

ë™ê²°í•˜ëŠ” ì½”ë“œ

```python
base_model.trainable = False
```


----

# ìƒˆ ë ˆì´ì–´ ì¶”ê°€
íŠ¸ë ˆì´ë‹ ê°€ëŠ¥í•œ ìƒˆ ë ˆì´ì–´ë¥¼ ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ì— ì¶”ê°€      
* ìƒˆ ë ˆì´ì–´: ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ë ˆì´ì–´ì˜ í”¼ì²˜ë¥¼ ì·¨í•´ ìƒˆ ë°ì´í„°ì„¸íŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡ìœ¼ë¡œ ë³€í™˜

**[ì¶”ê°€í•  ë ˆì´ì–´]**    
* **[í’€ë§ ë ˆì´ì–´](https://yerimoh.github.io/DL8/#%ED%92%80%EB%A7%81pooling-%EA%B3%84%EC%B8%B5)**      
* **ë§ˆì§€ë§‰ ë ˆì´ì–´**: Boì¸ì§€ ì•„ë‹Œì§€ë¥¼ ë¶„ë¥˜    

```python
inputs = keras.Input(shape=(224, 224, 3))
# Separately from setting trainable on the model, we set training to False 
x = base_model(inputs, training=False)
x = keras.layers.GlobalAveragePooling2D()(x)
# A Dense classifier with a single unit (binary classification)
outputs = keras.layers.Dense(1)(x)
model = keras.Model(inputs, outputs)
```

ê·¸ëŸ¼ ì¶”ê°€ëœ ëª¨ë¸ì„ ì‚´í´ë³´ê² ë‹¤

```python
model.summary()
```

<details>
<summary>ğŸ‘€ ê²°ê³¼ ë³´ê¸° </summary>
<div markdown="1">


```python
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
vgg16 (Model)                (None, 7, 7, 512)         14714688  
_________________________________________________________________
global_average_pooling2d (Gl (None, 512)               0         
_________________________________________________________________
dense (Dense)                (None, 1)                 513       
=================================================================
Total params: 14,715,201
Trainable params: 513
Non-trainable params: 14,714,688
_________________________________________________________________
```

</div>
</details>

â” ê·¸ëŸ°ë° ì¤‘ê°„ ë ˆì´ì–´ë“¤ì´ ëª¨ë‘ ì–´ë””ê°”ë‚˜ìš” â”     
```vgg16 (Model)```ë‚´ë¶€ ë ˆì´ì–´ ì „ì²´ë¥¼ í‘œì‹œí•˜ëŠ” ëŒ€ì‹  vgg16 ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ ëª¨ë¸ì„ í•˜ë‚˜ì˜ ìœ ë‹›ìœ¼ë¡œ ë³´ì—¬ì¤Œ      

ë˜í•œ ```Non-trainable params: 14,714,688```ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ íŠ¸ë ˆì´ë‹ ë¶ˆê°€í•œ ë‹¤ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ë„ ìˆë‹¤     


-----

# ëª¨ë¸ ì»´íŒŒì¼
ì†ì‹¤ ë° ì§€í‘œ ì˜µì…˜ìœ¼ë¡œ ëª¨ë¸ì„ ì»´íŒŒì¼ í•„ìš”     
í•˜ì§€ë§Œ [ì „ ëª¨ë¸](https://yerimoh.github.io/DL8.5/#%EB%AA%A8%EB%8D%B8-%EC%BB%B4%ED%8C%8C%EC%9D%BC)ê³¼ëŠ” ë‹¤ë¥¸ ë°©ì‹ì„ ì·¨í•´ì•¼ í•œë‹¤.     
* ì „ ëª¨ë¸: ë‹¤ìˆ˜ì˜ ë²”ì£¼ ì¡´ì¬ â¡ ì†ì‹¤ ê³„ì‚°ì„ ìœ„í•œ **ë²”ì£¼í˜•** í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ë¥¼ ì„ íƒ      
* í˜„ì¬ëª¨ë¸: ë°”ì´ë„ˆë¦¬ ë¶„ë¥˜ ë¬¸ì œ(Boì¸ì§€ ì•„ë‹Œì§€ ì—¬ë¶€) â¡ **ë°”ì´ë„ˆë¦¬** í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ë¥¼ ì„ íƒ      
```from_logits=True``` : ì¶œë ¥ ê°’ì´ softmax ë“±ìœ¼ë¡œ **ì •ê·œí™”ë˜ì§€ ì•Šì•˜ìŒ**ì„ [ì†ì‹¤ í•¨ìˆ˜](https://yerimoh.github.io/DL3/#%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98loss-function)ì— ì•Œë¦¼       

```python
# Important to use binary crossentropy and binary accuracy as we now have a binary classification problem
model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])
```

---

# ë°ì´í„° ì¦ê°•
[ë°ì´í„° ì¦ê°• ë” ì•Œì•„ë³´ëŸ¬ ê°€ê¸°](https://yerimoh.github.io/DL9/)       
ë§¤ìš° ì‘ì€ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë‹¤ë£¨ê³  ìˆëŠ” ë§Œí¼ ë°ì´í„°ë¥¼ ì¦ê°•ì´ í•„ìˆ˜ì ì„     
* ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ì•½ê°„ ìˆ˜ì •í•˜ë©´ ëª¨ë¸ì´ ë³´ë‹¤ ê´‘ë²”ìœ„í•œ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•˜ê³  í•™ìŠµê°€ëŠ¥     
*  ë‹¨ìˆœíˆ íŠ¸ë ˆì´ë‹í•˜ëŠ” ì‚¬ì§„ë§Œ ê¸°ì–µí•˜ëŠ” ëŒ€ì‹  Boì˜ ìƒˆë¡œìš´ ì‚¬ì§„ì„ ì¸ì‹í•˜ëŠ” ë²•ì„ í•™ìŠµí•˜ëŠ” ë° ë„ì›€ì´ ë¨      

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# create a data generator
datagen = ImageDataGenerator(
        samplewise_center=True,  # set each sample mean to 0
        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.1, # Randomly zoom image 
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False) # we don't expect Bo to be upside-down so we will not flip vertically
```

----

# ë°ì´í„° ë¡œë“œ
ì§€ê¸ˆê¹Œì§€ ë¡œë“œí•œ ë°©ì‹    
* [MNIST](https://yerimoh.github.io/DL6/): Keras ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ì—ì„œ ë°”ë¡œ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ       
* [ìˆ˜í™” ë°ì´í„°ì„¸íŠ¸](https://yerimoh.github.io/DL6.5/): CSV íŒŒì¼    
* ì§€ê¸ˆ!:  Kerasì˜ ```flow_from_directory``` í•¨ìˆ˜ë¥¼ ì‚¬ìš©           

**[ì¤€ë¹„í•œ ì´ë¯¸ì§€ ì„¸íŠ¸ ì„¤ëª…]**   
ê°ì ì´ ì´ë¯¸ì§€ ì„¸íŠ¸ì˜ ì¢…ë¥˜ë¥¼ ì°¸ê³ í•˜ì—¬ ë¶„ë¥˜í•˜ê³ ìí•˜ëŠ” ë™ë¬¼ì˜ ì´ë¯¸ì§€ë“¤ì„ ì¤€ë¹„í•´ì£¼ì‹œë©´ ëœë‹¤    
* Boì¸ ì´ë¯¸ì§€ ë¥¼ ìœ„í•œ í´ë”   
* Boê°€ ì•„ë‹Œ ì´ë¯¸ì§€ë¥¼ ìœ„í•œ í´ë”    

```flow_from_directory```     
* ëª¨ë¸ì— ë§ê²Œ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ë³€ê²½(244x244í”½ì…€ ë° 3ì±„ë„)     
*  í´ë”ì—ì„œ ë°”ë¡œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œ       

```python
# load and iterate training dataset
train_it = datagen.flow_from_directory('data/presidential_doggy_door/train/', 
                                       target_size=(224, 224), 
                                       color_mode='rgb', 
                                       class_mode='binary', 
                                       batch_size=8)
# load and iterate validation dataset
valid_it = datagen.flow_from_directory('data/presidential_doggy_door/valid/', 
                                      target_size=(224, 224), 
                                      color_mode='rgb', 
                                      class_mode='binary', 
                                      batch_size=8)
```

---


# ëª¨ë¸ íŠ¸ë ˆì´ë‹
ëª¨ë¸ì„ íŠ¸ë ˆì´ë‹í•˜ê³  ì„±ëŠ¥ì„ í™•ì¸           
```steps_per_epoch```ì˜ ìˆ˜ë¥¼ ëª…í™•í•˜ê²Œ í•˜ëŠ” ê²ƒì´ ì¤‘ìš”     
```python
model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=20)
```

<details>
<summary>ğŸ‘€ ê²°ê³¼ ë³´ê¸° </summary>
<div markdown="1">

```python    
Epoch 1/20
12/12 [==============================] - 5s 428ms/step - loss: 1.1611 - binary_accuracy: 0.7500 - val_loss: 0.5092 - val_binary_accuracy: 0.8000
Epoch 2/20
12/12 [==============================] - 2s 204ms/step - loss: 0.3859 - binary_accuracy: 0.8681 - val_loss: 0.5454 - val_binary_accuracy: 0.7667
Epoch 3/20
12/12 [==============================] - 2s 133ms/step - loss: 0.3611 - binary_accuracy: 0.8791 - val_loss: 0.9003 - val_binary_accuracy: 0.7667
Epoch 4/20
12/12 [==============================] - 2s 153ms/step - loss: 0.2447 - binary_accuracy: 0.9688 - val_loss: 0.3580 - val_binary_accuracy: 0.9000
Epoch 5/20
12/12 [==============================] - 2s 130ms/step - loss: 0.1432 - binary_accuracy: 0.9231 - val_loss: 0.2620 - val_binary_accuracy: 0.9000
Epoch 6/20
12/12 [==============================] - 2s 148ms/step - loss: 0.0607 - binary_accuracy: 0.9890 - val_loss: 0.0933 - val_binary_accuracy: 0.9667
Epoch 7/20
12/12 [==============================] - 2s 153ms/step - loss: 0.0756 - binary_accuracy: 0.9792 - val_loss: 0.2147 - val_binary_accuracy: 0.9333
Epoch 8/20
12/12 [==============================] - 2s 133ms/step - loss: 0.0848 - binary_accuracy: 0.9560 - val_loss: 0.2267 - val_binary_accuracy: 0.9000
Epoch 9/20
12/12 [==============================] - 2s 135ms/step - loss: 0.0758 - binary_accuracy: 0.9780 - val_loss: 0.2275 - val_binary_accuracy: 0.8667
Epoch 10/20
12/12 [==============================] - 2s 138ms/step - loss: 0.0520 - binary_accuracy: 0.9583 - val_loss: 0.0993 - val_binary_accuracy: 0.9333
Epoch 11/20
12/12 [==============================] - 2s 164ms/step - loss: 0.0547 - binary_accuracy: 0.9890 - val_loss: 0.1716 - val_binary_accuracy: 0.9333
Epoch 12/20
12/12 [==============================] - 1s 118ms/step - loss: 0.0045 - binary_accuracy: 1.0000 - val_loss: 0.0145 - val_binary_accuracy: 1.0000
Epoch 13/20
12/12 [==============================] - 2s 149ms/step - loss: 0.0156 - binary_accuracy: 1.0000 - val_loss: 0.0671 - val_binary_accuracy: 0.9667
Epoch 14/20
12/12 [==============================] - 1s 125ms/step - loss: 0.0245 - binary_accuracy: 0.9890 - val_loss: 0.2151 - val_binary_accuracy: 0.9333
Epoch 15/20
12/12 [==============================] - 2s 148ms/step - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 0.0128 - val_binary_accuracy: 1.0000
Epoch 16/20
12/12 [==============================] - 2s 137ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9667
Epoch 17/20
12/12 [==============================] - 2s 154ms/step - loss: 0.0300 - binary_accuracy: 0.9780 - val_loss: 0.0037 - val_binary_accuracy: 1.0000
Epoch 18/20
12/12 [==============================] - 1s 120ms/step - loss: 6.2258e-04 - binary_accuracy: 1.0000 - val_loss: 0.0674 - val_binary_accuracy: 0.9667
Epoch 19/20
12/12 [==============================] - 2s 151ms/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.0331 - val_binary_accuracy: 1.0000
Epoch 20/20
12/12 [==============================] - 2s 131ms/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000
<tensorflow.python.keras.callbacks.History at 0x7f2c5802a940>       
```

</div>
</details>


  
íŠ¸ë ˆì´ë‹ ë° ê²€ì¦ ì •í™•ë„ ë‘˜ ë‹¤ ìƒë‹¹íˆ ë†’ë‹¤!!


---


# ëª¨ë¸ íŒŒì¸ íŠœë‹















